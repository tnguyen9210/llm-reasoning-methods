{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4eeddb-1d9e-4f0e-980a-3e51286da3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, psutil, gc\n",
    "import time \n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_palette(\"tab20\")\n",
    "colors = sns.color_palette(\"bright\")\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcf3f3b6-d27d-47af-a634-7229c124283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from vllm import LLM, SamplingParams, PoolingParams\n",
    "\n",
    "from sal.config import Config\n",
    "from sal.models.reward_models import PRM\n",
    "from sal.utils.score import aggregate_scores\n",
    "from sal.search.utils import build_conv, generate_k_steps, last\n",
    "\n",
    "from core.reward_models import RLHFFlow\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from core import best_of_n\n",
    "from utils.load_data import load_data_prm800k, load_train_data_prm800k\n",
    "from utils import grader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe05c4c3-d898-4f0a-b332-e7ea2e70b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir\n",
    "base_dir = '/groups/kjun/tnn/datasets/'\n",
    "\n",
    "# dataset path\n",
    "# data_dir = base_dir + \"/prm800k/math_splits\"\n",
    "data_dir = base_dir + \"/math500\"\n",
    "\n",
    "# llm and prm path\n",
    "llm_dir = base_dir + \"/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.Q4_K_M.gguf\"\n",
    "prm_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data-GGUF/Llama3.1-8B-PRM-Deepseek-Data.Q4_K_M.gguf\"\n",
    "\n",
    "llm_tokenizer_dir = base_dir + \"/Llama-3.2-1B-Instruct\"\n",
    "prm_tokenizer_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a7d0f-796a-403d-acd9-27533962c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"HuggingFaceH4/Llama-3.2-1B-Instruct-best-of-N-completions\" \n",
    "dataset_split = 'train'\n",
    "# config_name = \"HuggingFaceH4_MATH-500--T-0.8--top_p-1.0--n-256--max_tokens-2048--bsz-8--seed-0--agg_strategy-last\" \n",
    "config_name = \"HuggingFaceH4_MATH-500--T-0.8--top_p-1.0--n-256--max_tokens-2048--bsz-8--seed-0--agg_strategy-last\"\n",
    "\n",
    "dataset = load_dataset(dataset_name, split=dataset_split, name=config_name, cache_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "191b9348-5a9e-45f0-94fa-a4061424fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--- memory: 0.0\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(llm_tokenizer_dir)\n",
    "llm_tf = AutoModelForCausalLM.from_pretrained(llm_tokenizer_dir).to(\"cuda:3\")\n",
    "# model_regular.generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "gc.collect();torch.cuda.empty_cache();\n",
    "print('#--- memory:', torch.cuda.memory_allocated(0)/(1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63d686d8-825d-44e7-afbd-948e30e1d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "->\n",
      "## Step 1: Understand the problem\n",
      "The circle has center $Q$ and a radius of 14 inches. Two smaller semicircles are tangent to each other and to the larger semicircle. The problem asks for the radius of the smaller semicircle.\n",
      "\n",
      "->\n",
      "## Step 2: Recognize the relevant geometry\n",
      "The right angle formed by the radii with the common tangent lines is crucial. It implies a right-angled triangle $\triangle ABQ$, where $A$ is the center of the larger circle, $B$ is the point of tangency on the smaller semicircle, $Q$ is the center of the smaller circle, and $Q$ is the point of tangency with the larger semicircle.\n",
      "\n",
      "->\n",
      "## Step 3: Identify the right triangle\n",
      "To solve the problem efficiently, we can use the properties of right-angled triangles. We can see that $\triangle ABQ$ is an isosceles right triangle because both radii are of equal length.\n",
      "\n",
      "->\n",
      "## Step 4: Apply the Pythagorean Theorem\n",
      "Let's denote the radius of the smaller semicircle as $x$. Using the Pythagorean Theorem, we can relate the sides of the triangle. We know that $AQ = QB = 14$, and $AB = \\sqrt{14^2 + x^2}$. We can use the fact that $AB$ is the hypotenuse of the right triangle $\triangle ABQ$. We can thus write: $\\sqrt{14^2 + x^2} = \\sqrt{14^2 + 14^2}$\n",
      "\n",
      "->\n",
      "## Step 5: Solve for the radius of the smaller semicircle\n",
      "Now we can simplify the equation and solve for $x$: $\\sqrt{14^2 + x^2} = \\sqrt{2 \\cdot 14^2}$, $x = \\sqrt{2 \\cdot 14^2 - 14^2}$, $x = \\sqrt{28 \\cdot 14}$, $x = \\sqrt{392}$, $x = 14\\sqrt{2}$\n",
      "\n",
      "->\n",
      "The final answer is: oxed{14\\sqrt{2}}$\n"
     ]
    }
   ],
   "source": [
    "def split_steps(text):\n",
    "    # Find all start positions of steps\n",
    "    step_starts = [match.start() for match in re.finditer(r'## Step \\d+:', text)]\n",
    "    step_starts.append(len(text))  # Add end of text as final boundary\n",
    "\n",
    "    steps = []\n",
    "    for i in range(len(step_starts) - 1):\n",
    "        chunk = text[step_starts[i]:step_starts[i+1]]\n",
    "        steps.append(chunk.strip())\n",
    "\n",
    "    # Extend the last step to include final answer if present\n",
    "    if steps and r'\\boxed' in text:\n",
    "        # Append the last boxed line to the final step if not already included\n",
    "        final_answer_match = re.search(r'The final answer is:.*?\\\\boxed\\{.*?\\}', text)\n",
    "        if final_answer_match:\n",
    "            final_answer = final_answer_match.group(0).strip()\n",
    "            if final_answer not in steps[-1]:\n",
    "                steps[-1] += '\\n\\n' + final_answer\n",
    "\n",
    "    return steps\n",
    "\n",
    "def split_steps(text):\n",
    "    # Find all step headers and their positions\n",
    "    step_matches = list(re.finditer(r\"## Step \\d+\", text))\n",
    "    step_positions = [(m.start(), m.group(0)) for m in step_matches]\n",
    "\n",
    "    steps = []\n",
    "\n",
    "    # Extract each step block based on positions\n",
    "    for i in range(len(step_positions)):\n",
    "        start_idx = step_positions[i][0]\n",
    "        end_idx = step_positions[i + 1][0] if i + 1 < len(step_positions) else len(text)\n",
    "        # step_text = text[start_idx:end_idx]\n",
    "        step_text = text[start_idx:end_idx].strip()\n",
    "        steps.append(step_text)\n",
    "\n",
    "    if len(steps) == 0:\n",
    "        return steps \n",
    "\n",
    "    steps_adjusted = steps[:-1]\n",
    "    # print(steps_adjusted)\n",
    "    newlines = \"\\n\\n\"\n",
    "    # print(text)\n",
    "    # print(steps)\n",
    "    last_step = steps[-1].split(newlines)\n",
    "    # for step in last_step:\n",
    "    #     print(\"\\n->\")\n",
    "    #     print(step)\n",
    "    # print(last_step)\n",
    "    tmp_step = newlines.join(last_step[:-1])\n",
    "    tmp_step = tmp_step.strip()\n",
    "    steps_adjusted.append(tmp_step)\n",
    "    steps_adjusted.append(last_step[-1].strip())\n",
    "    \n",
    "    # for step in steps_adjusted:\n",
    "    #     print(\"\\n->\")\n",
    "    #     print(step)\n",
    "    # # print(steps)\n",
    "    # stop\n",
    "    # # Extract final answer sentence with \\boxed{}\n",
    "    # final_answer_match = re.search(r\"The final answer is:.*?\\\\boxed\\{.*?\\}\", text)\n",
    "    # final_answer = final_answer_match.group(0).strip() if final_answer_match else None\n",
    "\n",
    "    return steps_adjusted\n",
    "\n",
    "text = '''\n",
    "## Step 1: Understand the problem\n",
    "The circle has center $Q$ and a radius of 14 inches. Two smaller semicircles are tangent to each other and to the larger semicircle. The problem asks for the radius of the smaller semicircle.\n",
    "\n",
    "## Step 2: Recognize the relevant geometry\n",
    "The right angle formed by the radii with the common tangent lines is crucial. It implies a right-angled triangle $\\triangle ABQ$, where $A$ is the center of the larger circle, $B$ is the point of tangency on the smaller semicircle, $Q$ is the center of the smaller circle, and $Q$ is the point of tangency with the larger semicircle.\n",
    "\n",
    "## Step 3: Identify the right triangle\n",
    "To solve the problem efficiently, we can use the properties of right-angled triangles. We can see that $\\triangle ABQ$ is an isosceles right triangle because both radii are of equal length.\n",
    "\n",
    "## Step 4: Apply the Pythagorean Theorem\n",
    "Let's denote the radius of the smaller semicircle as $x$. Using the Pythagorean Theorem, we can relate the sides of the triangle. We know that $AQ = QB = 14$, and $AB = \\sqrt{14^2 + x^2}$. We can use the fact that $AB$ is the hypotenuse of the right triangle $\\triangle ABQ$. We can thus write: $\\sqrt{14^2 + x^2} = \\sqrt{14^2 + 14^2}$\n",
    "\n",
    "## Step 5: Solve for the radius of the smaller semicircle\n",
    "Now we can simplify the equation and solve for $x$: $\\sqrt{14^2 + x^2} = \\sqrt{2 \\cdot 14^2}$, $x = \\sqrt{2 \\cdot 14^2 - 14^2}$, $x = \\sqrt{28 \\cdot 14}$, $x = \\sqrt{392}$, $x = 14\\sqrt{2}$\n",
    "\n",
    "\n",
    "The final answer is: $\\boxed{14\\sqrt{2}}$\n",
    "'''\n",
    "steps = split_steps(text)\n",
    "for step in steps:\n",
    "    print(\"\\n->\")\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98dfb27-fdfc-4726-9294-c3310d771e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 3\n",
    "dataset_by_level = dataset.filter(lambda example: example['level'] == level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "780f96fa-76da-41fc-942a-e80ae8853336",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type float32 is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 92\u001b[0m\n\u001b[1;32m     88\u001b[0m             all_data\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fout:\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/__init__.py:179\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(skipkeys\u001b[38;5;241m=\u001b[39mskipkeys, ensure_ascii\u001b[38;5;241m=\u001b[39mensure_ascii,\n\u001b[1;32m    174\u001b[0m         check_circular\u001b[38;5;241m=\u001b[39mcheck_circular, allow_nan\u001b[38;5;241m=\u001b[39mallow_nan, indent\u001b[38;5;241m=\u001b[39mindent,\n\u001b[1;32m    175\u001b[0m         separators\u001b[38;5;241m=\u001b[39mseparators,\n\u001b[1;32m    176\u001b[0m         default\u001b[38;5;241m=\u001b[39mdefault, sort_keys\u001b[38;5;241m=\u001b[39msort_keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\u001b[38;5;241m.\u001b[39miterencode(obj)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/encoder.py:430\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m _floatstr(o)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/encoder.py:326\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_list\u001b[0;34m(lst, _current_indent_level)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 326\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type float32 is not JSON serializable"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "\n",
    "all_data = []\n",
    "for q_idx, data in enumerate(dataset_by_level):\n",
    "    if q_idx > 2:\n",
    "        continue\n",
    "    # pprint.pprint(data)\n",
    "    # print(len(data[\"scores\"]))\n",
    "    \n",
    "    gt_answer = data['answer']\n",
    "    # for i_idx in range(len(data['completions'])):\n",
    "    cnt = 0\n",
    "    for i_idx, (scores, completion) in enumerate(zip(data['scores'], data['completions'])):\n",
    "        # if depth >= len(scores):\n",
    "        #     continue\n",
    "        if i_idx > 5:\n",
    "            continue\n",
    "\n",
    "        steps = split_steps(completion)\n",
    "        if len(steps) == 0:\n",
    "            continue\n",
    "\n",
    "        if len(steps) != len(scores):\n",
    "            # print(\"errors\")\n",
    "            # print(len(scores))\n",
    "            # print(completion)\n",
    "            cnt += 1\n",
    "            continue\n",
    "        \n",
    "        c_answer = grader.extract_last_boxed_answer(completion)\n",
    "        # print(completion)\n",
    "        # print(c_answer)\n",
    "        is_correct = 0        \n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            # warnings.simplefilter(\"always\")  # Capture all warnings, even if ignored previously\n",
    "            if grader.grade_answer(c_answer, gt_answer):\n",
    "                is_correct = 1\n",
    "                \n",
    "            for warning in w:\n",
    "                print(completion)\n",
    "                print(warning)\n",
    "\n",
    "        current_text = \"\"\n",
    "        \n",
    "        for s_idx, step in enumerate(steps):\n",
    "            current_text += step \n",
    "            convs = [\n",
    "                build_conv(problem, current_text, config.system_prompt)\n",
    "            ]            \n",
    "\n",
    "            templated_convs = tokenizer.apply_chat_template(\n",
    "                convs,\n",
    "                add_generation_prompt=False,\n",
    "                continue_final_message=True,\n",
    "                tokenize=False,\n",
    "            )\n",
    "    \n",
    "            inputs = tokenizer(templated_convs[0], return_tensors=\"pt\").to(llm_tf.device)\n",
    "            outputs = llm_tf(**inputs, output_hidden_states=True)\n",
    "\n",
    "            # Get last_token_embeds\n",
    "            last_hidden_state = outputs.hidden_states[-1]\n",
    "            last_token_embeds = last_hidden_state[:, -1, :].squeeze(0).detach().cpu().numpy()\n",
    "            \n",
    "            # Compute otuput_log_prob\n",
    "            # Prepare labels: shift input_ids to the right by one\n",
    "            labels = inputs['input_ids'][:, 1:]   \n",
    "            shifted_logits = outputs.logits[:, :-1, :]\n",
    "            loss_fct = CrossEntropyLoss(reduction='sum')\n",
    "            completion_log_prob = -loss_fct(shifted_logits.view(-1, shifted_logits.size(-1)), labels.view(-1)).detach().cpu().numpy()\n",
    "            # completion_ppl = np.exp(completion_log_prob/len(labels))\n",
    "            # print(sent_ppl)\n",
    "            # print(loss)\n",
    "            # completion_log_probs.append(completion_log_prob)\n",
    "            # completion_ppls.append(completion_ppl)\n",
    "\n",
    "            x[\"problem\"] = problem\n",
    "            x[\"current_step\"] = current_text\n",
    "            x[\"step_num\"] = s_idx\n",
    "            x[\"is_correct\"] = is_correct\n",
    "            x[\"is_completed\"] = 1 if s_idx == len(steps) - 1 else 0 \n",
    "            x[\"gt\"] = gt_answer\n",
    "            x[\"pred\"] = c_answer\n",
    "            x[\"prm_score\"] = scores[s_idx]\n",
    "            x[\"embeds\"] = [a for a in last_token_embeds]\n",
    "\n",
    "            x = defaultdict()\n",
    "            all_data.append(x)\n",
    "\n",
    "\n",
    "with open(f\"results/{config_name}.json\", 'w', encoding = 'utf-8') as fout:\n",
    "    json.dump(all_data, fout, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
