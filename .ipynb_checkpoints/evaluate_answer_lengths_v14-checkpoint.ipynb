{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f10c28-3f2d-47c0-ace3-b7a5d1463ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Evaluate the performance of search algorithms \n",
    "Collect scores across all prompts and trials, and compute the overall statistics.\n",
    "'''\n",
    "\n",
    "import os, psutil, gc\n",
    "import time \n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "from scipy.stats import ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cae36f-3789-45cf-9533-1842d3c71779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sal.config import Config\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# from core import best_of_n\n",
    "from utils.load_data import load_data_prm800k\n",
    "from utils import grader \n",
    "from utils import grader2\n",
    "from utils import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24dfa33-ee28-4654-b0e1-24a1c4eff608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir\n",
    "base_dir = '/groups/kjun/tnn/datasets/'\n",
    "\n",
    "# dataset path\n",
    "data_dir = base_dir + \"/prm800k/math_splits\"\n",
    "\n",
    "# llm and prm path\n",
    "llm_dir = base_dir + \"/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.Q4_K_M.gguf\"\n",
    "prm_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data-GGUF/Llama3.1-8B-PRM-Deepseek-Data.Q4_K_M.gguf\"\n",
    "\n",
    "llm_tokenizer_dir = base_dir + \"/Llama-3.2-1B-Instruct\"\n",
    "prm_tokenizer_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a4e1bf-b56b-4874-98cf-0ed225567369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 43\n",
      "2: 90\n",
      "3: 105\n",
      "4: 128\n",
      "5: 134\n"
     ]
    }
   ],
   "source": [
    "#  load data \n",
    "data_by_levels = load_data_prm800k(data_dir)\n",
    "\n",
    "\n",
    "# ds_completions = load_completions(completions_dir)\n",
    "\n",
    "# load random_seeds     \n",
    "# random_seeds = np.loadtxt(\"random_seeds.txt\").astype(\"int64\")\n",
    "# random_seeds = [int(seed) for seed in random_seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fe95daa-90cc-4172-86b0-85d81d734248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecbae5bc-cb50-47a5-a8cd-7c5cf4fc5d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e4ab49c1b0439ea43f6eca7aa257e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b0a111f604450ca33dd15f6c6554aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passn_ncomps: 6.4 (±0.2)\n",
      "pass1b_ncomps: 10.9 (±0.5)\n",
      "passn_lengths: 10.0 (±0.5)\n",
      "pass1b_lengths: 10.3 (±0.5)\n"
     ]
    }
   ],
   "source": [
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException()\n",
    "\n",
    "def run_with_timeout(fn_extract_answer, fn_grade, completion, gt_answer, timeout=2):\n",
    "    # Set the signal handler for SIGALRM\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(timeout)  # Schedule an alarm after `timeout` seconds\n",
    "    try:\n",
    "        c_answer = fn_extract_answer(completion, 'math')\n",
    "        result = fn_grade(c_answer, gt_answer)\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout: {completion}\")\n",
    "        c_answer = None\n",
    "        result = None\n",
    "    finally:\n",
    "        signal.alarm(0)  # Cancel alarm if function returns early\n",
    "    return c_answer, result\n",
    "\n",
    "def evaluate_correctness_hf(data_dir, level, n=8, limit_budget=False):\n",
    "\n",
    "    # dataset = load_dataset(dataset_name, name=config_name, split=dataset_split, cache_dir=data_dir)\n",
    "    dataset = load_dataset(\"json\", data_files = data_dir, split='train')\n",
    "    dataset_by_level = dataset.filter(lambda example: example['level'] == int(level))\n",
    "\n",
    "    passn_ncomps = np.zeros((len(dataset_by_level)))\n",
    "    passn_lengths = np.zeros((len(dataset_by_level)))\n",
    "\n",
    "    pass1b_ncomps = np.zeros((len(dataset_by_level)))\n",
    "    pass1b_lengths = np.zeros((len(dataset_by_level)))\n",
    "    for q_idx, data in enumerate(dataset_by_level):\n",
    "        passn_completions = data[\"completions\"][:n]\n",
    "        pass1b_completions = data[\"completions\"]\n",
    "\n",
    "        passn_total_len = 0 \n",
    "        for cidx, completion in enumerate(passn_completions):\n",
    "            passn_total_len += len(completion.split(\"\\n\\n\"))\n",
    "            \n",
    "        pass1b_total_len = 0\n",
    "        for cidx, completion in enumerate(pass1b_completions):\n",
    "            pass1b_total_len += len(completion.split(\"\\n\\n\"))\n",
    "        \n",
    "\n",
    "        passn_ncomps[q_idx] = len(passn_completions)\n",
    "        pass1b_ncomps[q_idx] = len(pass1b_completions)\n",
    "        \n",
    "        passn_lengths[q_idx] = passn_total_len/len(passn_completions) if len(passn_completions) > 0 else 0\n",
    "        pass1b_lengths[q_idx] = pass1b_total_len/len(pass1b_completions) if len(pass1b_completions) > 0 else 0\n",
    "\n",
    "        \n",
    "    return passn_ncomps, pass1b_ncomps, passn_lengths, pass1b_lengths\n",
    "\n",
    "\n",
    "# general params\n",
    "config = Config()\n",
    "config.agg_strategy = 'last'\n",
    "config.n = 8\n",
    "config.beam_width = 2\n",
    "config.lookahead = 0\n",
    "config.num_iterations = 10\n",
    "config.sort_completed = False\n",
    "\n",
    "# diverse_select params\n",
    "config.lam = 10\n",
    "config.normalize_embeds = True\n",
    "\n",
    "level = '4'\n",
    "# num_questions = len(data_by_levels[level])\n",
    "# num_questions = 1\n",
    "num_trials = 2\n",
    "# print(f\"num_questions = {num_questions}\")\n",
    "\n",
    "config_name = \"bob--n-8--d-40--level-4--v11\"\n",
    "config_name = \"bob--v11--n-40--d-40--level-4\"\n",
    "\n",
    "all_passn_ncomps = []\n",
    "all_pass1b_ncomps = []\n",
    "all_passn_lengths = []\n",
    "all_pass1b_lengths = []\n",
    "for trial_idx in range(num_trials):\n",
    "    passn_ncomps, pass1b_ncomps, passn_lengths, pass1b_lengths = \\\n",
    "        evaluate_correctness_hf(f\"results/{config_name}/{config_name}--trial-{trial_idx}.jsonl\", level, config.n, limit_budget=False)\n",
    "    # print(passn_ncomps)\n",
    "    \n",
    "    all_passn_ncomps.append(passn_ncomps)\n",
    "    all_pass1b_ncomps.append(pass1b_ncomps)\n",
    "    all_passn_lengths.append(passn_lengths)\n",
    "    all_pass1b_lengths.append(pass1b_lengths)\n",
    "\n",
    "# print(passn_ncomps)\n",
    "# print(len(passn_ncomps))\n",
    "all_passn_ncomps = np.concatenate(all_passn_ncomps)\n",
    "all_pass1b_ncomps = np.concatenate(all_pass1b_ncomps)\n",
    "\n",
    "all_passn_lengths = np.concatenate(all_passn_lengths)\n",
    "all_pass1b_lengths = np.concatenate(all_pass1b_lengths)\n",
    "\n",
    "passn_ncomps_mean = np.mean(all_passn_ncomps)\n",
    "pass1b_ncomps_mean = np.mean(all_pass1b_ncomps)\n",
    "passn_lengths_mean = np.mean(all_passn_lengths)\n",
    "pass1b_lengths_mean = np.mean(all_pass1b_lengths)\n",
    "\n",
    "\n",
    "passn_ncomps_std = np.std(all_passn_ncomps, ddof=1)/np.sqrt(num_trials*128) # 128 is number of prompts for level 4 \n",
    "pass1b_ncomps_std = np.std(all_pass1b_ncomps, ddof=1)/np.sqrt(num_trials*128)\n",
    "passn_lengths_std = np.std(all_passn_lengths, ddof=1)/np.sqrt(num_trials*128)\n",
    "pass1b_lengths_std = np.std(all_pass1b_lengths, ddof=1)/np.sqrt(num_trials*128)\n",
    "\n",
    "# print(passn_correctness)\n",
    "# print(pass1b_correctness)\n",
    "# print(weighted1b_correctness)\n",
    "# print(pass1b_correctness_mean)\n",
    "# print(pass1b_correctness_std)\n",
    "\n",
    "print(f\"passn_ncomps: {passn_ncomps_mean:0.1f} (\\u00B1{passn_ncomps_std:0.1f})\")\n",
    "print(f\"pass1b_ncomps: {pass1b_ncomps_mean:0.1f} (\\u00B1{pass1b_ncomps_std:0.1f})\")\n",
    "print(f\"passn_lengths: {passn_lengths_mean:0.1f} (\\u00B1{passn_lengths_std:0.1f})\")\n",
    "print(f\"pass1b_lengths: {pass1b_lengths_mean:0.1f} (\\u00B1{pass1b_lengths_std:0.1f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a5334-a853-4ae8-8f20-8a969e5ff81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
