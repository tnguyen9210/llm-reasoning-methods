{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4eeddb-1d9e-4f0e-980a-3e51286da3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, psutil, gc\n",
    "import time \n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcf3f3b6-d27d-47af-a634-7229c124283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from vllm import LLM, SamplingParams, PoolingParams\n",
    "\n",
    "from sal.config import Config\n",
    "from sal.models.reward_models import PRM\n",
    "from sal.utils.score import aggregate_scores\n",
    "\n",
    "from core.reward_models import RLHFFlow\n",
    "\n",
    "from core import best_of_n\n",
    "from utils.load_data import load_data_prm800k, load_train_data_prm800k\n",
    "from utils import grader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe05c4c3-d898-4f0a-b332-e7ea2e70b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir\n",
    "base_dir = '/groups/kjun/tnn/datasets/'\n",
    "\n",
    "# dataset path\n",
    "data_dir = base_dir + \"/prm800k/math_splits\"\n",
    "\n",
    "# llm and prm path\n",
    "llm_dir = base_dir + \"/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.Q4_K_M.gguf\"\n",
    "prm_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data-GGUF/Llama3.1-8B-PRM-Deepseek-Data.Q4_K_M.gguf\"\n",
    "\n",
    "llm_tokenizer_dir = base_dir + \"/Llama-3.2-1B-Instruct\"\n",
    "prm_tokenizer_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf9de99-5413-4471-8ae9-e2b6f4ffc6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(llm_tokenizer_dir)\n",
    "# llm_tf = AutoModelForCausalLM.from_pretrained(llm_tokenizer_dir).to(\"cuda:1\")\n",
    "# # model_regular.generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "# gc.collect();torch.cuda.empty_cache();\n",
    "# print('#--- memory:', torch.cuda.memory_allocated(0)/(1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e9d4a56-d9e9-42c5-b069-01c2a7165278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f23bf9b6bd54381b452c1f20bc89c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--- memory: 0.0\n",
      "#--- memory: 0.0\n"
     ]
    }
   ],
   "source": [
    "prm = RLHFFlow(model_path=prm_tokenizer_dir, device_map='cuda:2')\n",
    "\n",
    "gc.collect();torch.cuda.empty_cache();\n",
    "print('#--- memory:', torch.cuda.memory_allocated(0)/(1024**3))\n",
    "print('#--- memory:', torch.cuda.memory_allocated(1)/(1024**3))\n",
    "# print('#--- memory:', torch.cuda.memory_allocated(2)/(1024**3))\n",
    "# print('#--- memory:', torch.cuda.memory_allocated(3)/(1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2d165ad-58d0-449c-a634-4399b4713634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 958\n",
      "2: 2152\n",
      "3: 2619\n",
      "4: 2776\n",
      "5: 3495\n"
     ]
    }
   ],
   "source": [
    "#  load data \n",
    "data_by_levels = load_train_data_prm800k(data_dir)\n",
    "\n",
    "# ds_completions = load_completions(completions_dir)\n",
    "\n",
    "# load random_seeds     \n",
    "# random_seeds = np.loadtxt(\"random_seeds.txt\").astype(\"int64\")\n",
    "# random_seeds = [int(seed) for seed in random_seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c5cb29-c4e7-4dec-8ab7-8c976f5423a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint.pprint(data_by_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea1baed-dbc1-4bfb-8775-2ef5be1f2a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_questions = 2776\n",
      "trial_idx = 0\n",
      "2\n",
      "trial_idx = 1\n",
      "2\n",
      "trial_idx = 2\n",
      "2\n",
      "trial_idx = 3\n",
      "2\n",
      "trial_idx = 4\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 1 column 78985928 (char 78985927)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 98\u001b[0m\n\u001b[1;32m     92\u001b[0m bon_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/generate_bon_prm800k_train_level4_n16_v11.jsonl\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# sd_dir = f\"results/generate_sd_prm800k_level{level}_n{config.n}_bw{config.beam_width}_depth{config.num_iterations}_lam{config.lam}_{config.normalize_embeds}_v11.jsonl\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# sd_dir = f\"results/generate_beam_prm800k_level4_n8_bw2_depth40_v11.jsonl\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# print(sd_dir)\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mexamine_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbon_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_by_levels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_questions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# res = examine_completions(prm, sd_dir, data_by_levels[level], num_trials, num_questions, config.n)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mexamine_completions\u001b[0;34m(prm, data_dir, data_by_levels, num_trials, num_questions, num_budgets)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trial_idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_trials:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m trial_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(trial_data))\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# scores = prm.score(batch_of_questions, trial_data[\"completions\"][:num_questions])\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# agg_scores = [\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     [aggregate_scores(s, config.agg_strategy) for s in score] for score in scores\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#     # all_correctness[trial_idx][q_idx] = is_correct\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#     # all_correctness.append(is_correct)\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 1 column 78985928 (char 78985927)"
     ]
    }
   ],
   "source": [
    "def examine_completions(prm, data_dir, data_by_levels, num_trials, num_questions, num_budgets=None):\n",
    "\n",
    "    with open(data_dir, 'r', encoding='utf-8') as fin:\n",
    "        # all_correctness = []\n",
    "        # all_correctness = np.zeros((num_trials, len(data_by_levels)))\n",
    "        # gt_answers = []\n",
    "        # print(len(fin))\n",
    "        trial_idx = 0\n",
    "        for line in fin:\n",
    "            print(f\"trial_idx = {trial_idx}\")\n",
    "            # print(num_trials)\n",
    "            if trial_idx >= num_trials:\n",
    "                break\n",
    "                \n",
    "            trial_data = json.loads(line)\n",
    "            print(len(trial_data))\n",
    "            \n",
    "            # scores = prm.score(batch_of_questions, trial_data[\"completions\"][:num_questions])\n",
    "            # agg_scores = [\n",
    "            #     [aggregate_scores(s, config.agg_strategy) for s in score] for score in scores\n",
    "            # ]\n",
    "            # print(\n",
    "            \n",
    "            # for q_idx in range(num_questions):\n",
    "            #     print(f\"\\n-> question idx = {q_idx}\")\n",
    "            #     question = data_by_levels[q_idx]['problem']\n",
    "            #     print(question)\n",
    "            #     if num_budgets is not None:\n",
    "            #         completions = trial_data['completions'][q_idx][:num_budgets]\n",
    "            #     else:\n",
    "            #         completions = trial_data['completions'][q_idx]\n",
    "\n",
    "            #     # print(data_by_levels[q_idx]['problem'])\n",
    "            #     # questions = [data_by_levels[q_idx]['problem']]\n",
    "            #     # print(len(completions))\n",
    "                \n",
    "            #     scores = prm.score([question], [completions])\n",
    "            #     # print(len(scores))\n",
    "            #     # print(scores)\n",
    "                \n",
    "            #     agg_scores = [\n",
    "            #         [aggregate_scores(s, config.agg_strategy) for s in score] for score in scores\n",
    "            #     ]\n",
    "            #     # print(len(agg_scores))\n",
    "            #     # print(agg_scores)\n",
    "            #     # stop\n",
    "\n",
    "            #     gt_answer = data_by_levels[q_idx]['answer']\n",
    "            #     print(f\"actual answer = {gt_answer}\")\n",
    "            #     is_correct = False\n",
    "            #     for cidx, completion in enumerate(completions):\n",
    "            #         print(f\"\\n -> completion idx = {cidx}\")\n",
    "                    \n",
    "            #         c_answer = grader.extract_last_boxed_answer(completion)\n",
    "            #         if grader.grade_answer(c_answer, gt_answer):\n",
    "            #             is_correct = True\n",
    "            #             break\n",
    "\n",
    "            #         print(f\"completion answer = {c_answer}\")\n",
    "            #         print(f\"scores = {scores[0][cidx]}\")\n",
    "            #         print(f\"agg_scores = {agg_scores[0][cidx]}\")\n",
    "            #         print(completion)\n",
    "\n",
    "            #     # all_correctness[trial_idx][q_idx] = is_correct\n",
    "            #     # all_correctness.append(is_correct)\n",
    "\n",
    "            trial_idx += 1\n",
    "            \n",
    "\n",
    "    # return all_correctness\n",
    "\n",
    "\n",
    "# general params\n",
    "config = Config()\n",
    "config.agg_strategy = 'last'\n",
    "config.n = 16\n",
    "config.beam_width = 2\n",
    "config.lookahead = 0\n",
    "config.num_iterations = 2\n",
    "config.sort_completed = False\n",
    "\n",
    "# diverse_select params\n",
    "config.lam = 10\n",
    "config.normalize_embeds = True\n",
    "\n",
    "level = '4'\n",
    "num_questions = len(data_by_levels[level])\n",
    "# num_questions = 2\n",
    "num_trials = 5\n",
    "print(f\"num_questions = {num_questions}\")\n",
    "\n",
    "bon_dir = \"results/generate_bon_prm800k_train_level4_n16_v11.jsonl\" \n",
    "# sd_dir = f\"results/generate_sd_prm800k_level{level}_n{config.n}_bw{config.beam_width}_depth{config.num_iterations}_lam{config.lam}_{config.normalize_embeds}_v11.jsonl\"\n",
    "\n",
    "# sd_dir = f\"results/generate_beam_prm800k_level4_n8_bw2_depth40_v11.jsonl\"\n",
    "# print(sd_dir)\n",
    "\n",
    "res = examine_completions(prm, bon_dir, data_by_levels[level], num_trials, num_questions)\n",
    "# res = examine_completions(prm, sd_dir, data_by_levels[level], num_trials, num_questions, config.n)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
