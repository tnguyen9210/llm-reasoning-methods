{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f10c28-3f2d-47c0-ace3-b7a5d1463ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, psutil, gc\n",
    "import time \n",
    "import json\n",
    "import pprint\n",
    "\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cae36f-3789-45cf-9533-1842d3c71779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from vllm import LLM, SamplingParams, PoolingParams\n",
    "\n",
    "from sal.config import Config\n",
    "from sal.models.reward_models import PRM\n",
    "from sal.utils.score import aggregate_scores\n",
    "\n",
    "# from core.reward_models import RLHFFlow, SkyworkO1\n",
    "from core import reward_models\n",
    "\n",
    "from core import best_of_n\n",
    "from utils.load_data import load_data_prm800k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd9a9bc-0205-4b75-8d7a-d1027487be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24dfa33-ee28-4654-b0e1-24a1c4eff608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir\n",
    "base_dir = '/groups/kjun/tnn/datasets/'\n",
    "\n",
    "# dataset path\n",
    "data_dir = base_dir + \"/prm800k/math_splits\"\n",
    "\n",
    "# llm and prm path\n",
    "llm_dir = base_dir + \"/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.Q4_K_M.gguf\"\n",
    "prm_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data-GGUF/Llama3.1-8B-PRM-Deepseek-Data.Q4_K_M.gguf\"\n",
    "\n",
    "llm_tokenizer_dir = base_dir + \"/Llama-3.2-1B-Instruct\"\n",
    "prm_tokenizer_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b42d59a-2eb5-4be7-812a-e4705522df4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs = ['0', '1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "if torch.cuda.is_available():\n",
    "    GPUs = os.environ.get('CUDA_VISIBLE_DEVICES', \"0\").split(',')\n",
    "    print(f\"GPUs = {GPUs}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d660ac45-b760-43eb-90fd-8b199803aba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sal.models.skywork_o1_prm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward_models\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/py311/lib/python3.11/importlib/__init__.py:169\u001b[0m, in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec not found for the module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 169\u001b[0m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The module may have replaced itself in sys.modules!\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[name]\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:621\u001b[0m, in \u001b[0;36m_exec\u001b[0;34m(spec, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/tnn1/LLMs/llm-reasoning-methods/core/reward_models.py:12\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m      6\u001b[0m     AutoTokenizer,\n\u001b[1;32m      7\u001b[0m     PreTrainedModel,\n\u001b[1;32m      8\u001b[0m     PreTrainedTokenizer,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mskywork_o1_prm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     13\u001b[0m     derive_step_rewards,\n\u001b[1;32m     14\u001b[0m     prepare_batch_input_for_model,\n\u001b[1;32m     15\u001b[0m     prepare_input,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mskywork_o1_prm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprm_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SkyworkPRMModel\n\u001b[1;32m     19\u001b[0m CANDIDATE_TOKENS \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m648\u001b[39m, \u001b[38;5;241m387\u001b[39m]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sal.models.skywork_o1_prm'"
     ]
    }
   ],
   "source": [
    "importlib.reload(reward_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c733bc0-30b0-439c-a2b4-a6288b620083",
   "metadata": {},
   "outputs": [],
   "source": [
    "prm_dir = base_dir + \"/Skywork-o1-Open-PRM-Qwen-2.5-1.5B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd04a282-5d08-4831-affb-35bf31080db3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SkyworkPRMModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prm \u001b[38;5;241m=\u001b[39m \u001b[43mreward_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSkyworkO1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprm_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tnn1/LLMs/llm-reasoning-methods/core/reward_models.py:27\u001b[0m, in \u001b[0;36mPRM.__init__\u001b[0;34m(self, model_path, device_map, **model_kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path \u001b[38;5;241m=\u001b[39m model_path\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_map \u001b[38;5;241m=\u001b[39m device_map\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_and_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tnn1/LLMs/llm-reasoning-methods/core/reward_models.py:202\u001b[0m, in \u001b[0;36mSkyworkO1.load_model_and_tokenizer\u001b[0;34m(self, **model_kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_model_and_tokenizer\u001b[39m(\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[1;32m    198\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[PreTrainedModel, PreTrainedTokenizer]:\n\u001b[1;32m    199\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path, trust_remote_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     )\n\u001b[0;32m--> 202\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSkyworkPRMModel\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_path,\n\u001b[1;32m    204\u001b[0m         device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_map,\n\u001b[1;32m    205\u001b[0m         torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16,\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    207\u001b[0m     )\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SkyworkPRMModel' is not defined"
     ]
    }
   ],
   "source": [
    "prm = reward_models.SkyworkO1(model_path=prm_dir, device_map=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a129354-c8ce-4c23-bef0-6684bb9d73e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3565dafea7450283c243be94fcb0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)lama3.1-8B-PRM-Deepseek-Data.Q4_K_M.gguf:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e257e0e3e5f4e8a8faa713353d39b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting and de-quantizing GGUF tensors...:   0%|          | 0/292 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f9a0f2d68a4bea928b5ee1d72d561c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--- memory: 14.95752763748169\n",
      "#--- memory: 0.0\n"
     ]
    }
   ],
   "source": [
    "prm = RLHFFlow(model_path=prm_tokenizer_dir, device_map='cuda:0')\n",
    "\n",
    "gc.collect();torch.cuda.empty_cache();\n",
    "print('#--- memory:', torch.cuda.memory_allocated(0)/(1024**3))\n",
    "print('#--- memory:', torch.cuda.memory_allocated(1)/(1024**3))\n",
    "# print('#--- memory:', torch.cuda.memory_allocated(2)/(1024**3))\n",
    "# print('#--- memory:', torch.cuda.memory_allocated(3)/(1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac147209-6f17-4d7d-a94d-bdaeccbba42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--- memory: 14.96546220779419\n",
      "#--- memory: 0.0\n"
     ]
    }
   ],
   "source": [
    "# del(prm)\n",
    "gc.collect();torch.cuda.empty_cache();\n",
    "print('#--- memory:', torch.cuda.memory_allocated(0)/(1024**3))\n",
    "print('#--- memory:', torch.cuda.memory_allocated(1)/(1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a4e1bf-b56b-4874-98cf-0ed225567369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 43\n",
      "2: 90\n",
      "3: 105\n",
      "4: 128\n",
      "5: 134\n"
     ]
    }
   ],
   "source": [
    "#  load data \n",
    "data_by_levels = load_data_prm800k(data_dir)\n",
    "\n",
    "\n",
    "# ds_completions = load_completions(completions_dir)\n",
    "\n",
    "# load random_seeds     \n",
    "# random_seeds = np.loadtxt(\"random_seeds.txt\").astype(\"int64\")\n",
    "# random_seeds = [int(seed) for seed in random_seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97197039-298e-407e-ae80-876cc65dd7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_questions = 20\n",
      "trial 0\n",
      "it takes 2.3245s per question\n",
      "it takes 46.4892s per trial\n",
      "it takes 46.4946s in total\n"
     ]
    }
   ],
   "source": [
    "# general params\n",
    "config = Config()\n",
    "config.n = 16\n",
    "config.agg_strategy = 'last'\n",
    "\n",
    "level = '1'\n",
    "num_questions = len(data_by_levels[level])\n",
    "num_questions = 20\n",
    "num_trials = 1\n",
    "print(f\"num_questions = {num_questions}\")\n",
    "\n",
    "# get batch of questions\n",
    "batch_of_questions = [data_by_levels[level][q_idx]['problem'] for q_idx in range(num_questions)]\n",
    "\n",
    "# load completions \n",
    "completions_dir = f\"results/generate_bon_prm800k_level{level}_n16_v11.jsonl\"\n",
    "scores_dir = f\"../results/scores_bon_prm800k_level{level}_n16_v11.jsonl\"\n",
    "\n",
    "# compute results\n",
    "fout = open(scores_dir, 'w', encoding = 'utf-8')\n",
    "start_time = time.time()\n",
    "with open(scores_dir, 'w', encoding = 'utf-8') as fout:\n",
    "    with open(completions_dir, 'r', encoding = 'utf-8') as fin:\n",
    "        trial_idx = 0\n",
    "        for line in fin:\n",
    "            if trial_idx >= num_trials:\n",
    "                break\n",
    "                \n",
    "            trial_data = json.loads(line)\n",
    "    \n",
    "            # Compute the scores of completions\n",
    "            # print(len(trial_data[\"completions\"]))\n",
    "            # print(len(batch_of_questions))\n",
    "            # print(trial_data[\"completions\"][0][0])\n",
    "            scores = prm.score(batch_of_questions, trial_data[\"completions\"][:num_questions])\n",
    "            agg_scores = [\n",
    "                [aggregate_scores(s, config.agg_strategy) for s in score] for score in scores\n",
    "            ]\n",
    "            # print(agg_scores)\n",
    "            \n",
    "            trial_data[\"agg_scores\"] = agg_scores\n",
    "            # print(trial_data.keys())\n",
    "            json.dump(trial_data, fout)\n",
    "            fout.write('\\n')\n",
    "    \n",
    "            # compute the time\n",
    "            if trial_idx % 1 == 0:\n",
    "                total_time = time.time() - start_time\n",
    "                time_per_trial = total_time/(trial_idx+1)\n",
    "                time_per_question = time_per_trial/num_questions\n",
    "                print(f\"trial {trial_idx}\")\n",
    "                print(f\"it takes {time_per_question:0.4f}s per question\")\n",
    "                print(f\"it takes {time_per_trial:0.4f}s per trial\")\n",
    "    \n",
    "            trial_idx += 1\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"it takes {total_time:0.4f}s in total\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
