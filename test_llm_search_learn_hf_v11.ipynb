{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Pc7iGaUtZy3o"},"outputs":[],"source":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GvZ_3BeHak2d","outputId":"9b44973d-7eef-492a-ec8b-4008654e731b","executionInfo":{"status":"ok","timestamp":1740609122260,"user_tz":420,"elapsed":556,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ltI9XjUm4XbM"},"outputs":[],"source":["import os, sys\n","nb_path = '/content/notebooks'\n","os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuTqIy-Ly7pM"},"outputs":[],"source":["from huggingface_hub import login\n","# TODO: replace below with your login code.\n","login()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3IzufdFUsU7","outputId":"f3f1878c-0ea4-46ab-ba92-c6009cb3ba16","executionInfo":{"status":"ok","timestamp":1740589429079,"user_tz":420,"elapsed":8,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Colab Notebooks/packages/search-and-learn\n"]}],"source":["# TODO: change this path to your code location (the huggingface's code)\n","%cd /content/notebooks/packages/search-and-learn/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Rq9uEwqxGhS","outputId":"4b400782-492a-4014-d622-2b41f0e51c0a","executionInfo":{"status":"ok","timestamp":1740589409011,"user_tz":420,"elapsed":166556,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/drive/My%20Drive/Colab%20Notebooks/packages/search-and-learn\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (1.3.0)\n","Collecting pebble (from search-and-learn==0.1.0)\n","  Downloading Pebble-5.1.0-py3-none-any.whl.metadata (3.6 kB)\n","Collecting latex2sympy2==1.9.1 (from search-and-learn==0.1.0)\n","  Downloading latex2sympy2-1.9.1-py3-none-any.whl.metadata (6.6 kB)\n","Collecting word2number (from search-and-learn==0.1.0)\n","  Downloading word2number-1.1.zip (9.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (4.48.3)\n","Collecting fastapi (from search-and-learn==0.1.0)\n","  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n","Collecting hf_transfer (from search-and-learn==0.1.0)\n","  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n","Requirement already satisfied: sympy>=1.4 in /usr/local/lib/python3.11/dist-packages (from latex2sympy2==1.9.1->search-and-learn==0.1.0) (1.13.1)\n","Collecting antlr4-python3-runtime==4.7.2 (from latex2sympy2==1.9.1->search-and-learn==0.1.0)\n","  Downloading antlr4-python3-runtime-4.7.2.tar.gz (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting vllm==0.6.3 (from search-and-learn==0.1.0)\n","  Downloading vllm-0.6.3-cp38-abi3-manylinux1_x86_64.whl.metadata (10 kB)\n","Collecting ruff (from search-and-learn==0.1.0)\n","  Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting isort (from search-and-learn==0.1.0)\n","  Downloading isort-6.0.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from search-and-learn==0.1.0) (8.3.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (1.26.4)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (4.67.1)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (9.0.0)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.21.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (4.25.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (3.11.12)\n","Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (1.61.1)\n","Collecting uvicorn[standard] (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (2.10.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (11.1.0)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.21.1)\n","Collecting prometheus-fastapi-instrumentator>=7.0.0 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl.metadata (13 kB)\n","Collecting tiktoken>=0.6.0 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting lm-format-enforcer==0.10.6 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading lm_format_enforcer-0.10.6-py3-none-any.whl.metadata (16 kB)\n","Collecting outlines<0.1,>=0.0.43 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading outlines-0.0.46-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (4.12.2)\n","Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (3.17.0)\n","Collecting partial-json-parser (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (24.0.1)\n","Collecting msgspec (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n","Collecting gguf==0.10.0 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading gguf-0.10.0-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (8.6.1)\n","Collecting mistral-common>=1.4.4 (from mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading mistral_common-1.5.3-py3-none-any.whl.metadata (4.5 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (6.0.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm==0.6.3->search-and-learn==0.1.0) (0.8.1)\n","Collecting ray>=2.9 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (18 kB)\n","Collecting nvidia-ml-py (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl.metadata (8.7 kB)\n","Collecting torch==2.4.0 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.19 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n","Collecting xformers==0.0.27.post2 (from vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n","Collecting interegular>=0.3.2 (from lm-format-enforcer==0.10.6->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm==0.6.3->search-and-learn==0.1.0) (24.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (2024.10.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==3.0.0 (from torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (12.5.82)\n","Collecting starlette<0.46.0,>=0.40.0 (from fastapi->search-and-learn==0.1.0)\n","  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.47.0->search-and-learn==0.1.0) (0.28.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.47.0->search-and-learn==0.1.0) (2024.11.6)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.47.0->search-and-learn==0.1.0) (0.5.2)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->search-and-learn==0.1.0) (2.0.0)\n","Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->search-and-learn==0.1.0) (1.5.0)\n","Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (4.23.0)\n","Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (4.11.0.86)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (1.3.1)\n","Collecting lark (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (1.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (3.1.1)\n","Collecting diskcache (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (0.61.0)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (0.36.2)\n","Collecting datasets (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n","Collecting pycountry (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n","Collecting pyairports (from outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading pyairports-2.1.1-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (2.27.2)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (8.1.8)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (1.1.0)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (1.3.2)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm==0.6.3->search-and-learn==0.1.0) (1.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.6.3->search-and-learn==0.1.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.6.3->search-and-learn==0.1.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.6.3->search-and-learn==0.1.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm==0.6.3->search-and-learn==0.1.0) (2025.1.31)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.4->latex2sympy2==1.9.1->search-and-learn==0.1.0) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (2.4.6)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (25.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm==0.6.3->search-and-learn==0.1.0) (1.18.3)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->vllm==0.6.3->search-and-learn==0.1.0) (3.21.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0) (0.14.0)\n","Collecting httptools>=0.6.3 (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting python-dotenv>=0.13 (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles>=0.13 (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm==0.6.3->search-and-learn==0.1.0) (14.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm==0.6.3->search-and-learn==0.1.0) (1.0.7)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (2024.10.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm==0.6.3->search-and-learn==0.1.0) (0.22.3)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2.2.2)\n","Collecting xxhash (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0->vllm==0.6.3->search-and-learn==0.1.0) (3.0.2)\n","Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (0.44.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm==0.6.3->search-and-learn==0.1.0) (1.17.0)\n","Downloading latex2sympy2-1.9.1-py3-none-any.whl (89 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.8/89.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading vllm-0.6.3-cp38-abi3-manylinux1_x86_64.whl (193.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gguf-0.10.0-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lm_format_enforcer-0.10.6-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl (20.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m146.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m111.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading isort-6.0.0-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Pebble-5.1.0-py3-none-any.whl (36 kB)\n","Downloading ruff-0.9.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mistral_common-1.5.3-py3-none-any.whl (6.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading outlines-0.0.46-py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prometheus_fastapi_instrumentator-7.0.2-py3-none-any.whl (18 kB)\n","Downloading ray-2.42.1-cp311-cp311-manylinux2014_x86_64.whl (67.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading partial_json_parser-0.2.1.1.post5-py3-none-any.whl (10 kB)\n","Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interegular-0.3.3-py37-none-any.whl (23 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lark-1.2.2-py3-none-any.whl (111 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyairports-2.1.1-py3-none-any.whl (371 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m371.7/371.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m115.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: search-and-learn, antlr4-python3-runtime, word2number\n","  Building editable for search-and-learn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for search-and-learn: filename=search_and_learn-0.1.0-0.editable-py3-none-any.whl size=8667 sha256=80160ed97417d522d57f0bf63e05cae989d35f58eb4b149f48a937ad38d6bcf7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4_ut0__z/wheels/94/83/6c/76c30ba93d20550ab7f3c76f0ed445f2212ddbdac089d4c672\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.7.2-py3-none-any.whl size=140931 sha256=bd5f766d4019760def790c2d899c06dc085e84177879fd0adefa1f7e008317db\n","  Stored in directory: /root/.cache/pip/wheels/c4/f4/c7/71f768e561b9cc8bce3160d1229728d0d77fd5fd6d4f5d960b\n","  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=42c58aa994091580f57e30f1de7ad6a5993303a40f19d790d12738b90690acae\n","  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n","Successfully built search-and-learn antlr4-python3-runtime word2number\n","Installing collected packages: word2number, pyairports, nvidia-ml-py, antlr4-python3-runtime, xxhash, uvloop, uvicorn, triton, ruff, python-dotenv, pycountry, pebble, partial-json-parser, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, lark, isort, interegular, httptools, hf_transfer, gguf, diskcache, dill, watchfiles, tiktoken, starlette, nvidia-cusolver-cu12, nvidia-cudnn-cu12, multiprocess, latex2sympy2, torch, prometheus-fastapi-instrumentator, lm-format-enforcer, fastapi, xformers, torchvision, ray, mistral-common, datasets, search-and-learn, outlines, vllm\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.1.0\n","    Uninstalling triton-3.1.0:\n","      Successfully uninstalled triton-3.1.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu124\n","    Uninstalling torch-2.5.1+cu124:\n","      Successfully uninstalled torch-2.5.1+cu124\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.20.1+cu124\n","    Uninstalling torchvision-0.20.1+cu124:\n","      Successfully uninstalled torchvision-0.20.1+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed antlr4-python3-runtime-4.7.2 datasets-3.3.2 dill-0.3.8 diskcache-5.6.3 fastapi-0.115.8 gguf-0.10.0 hf_transfer-0.1.9 httptools-0.6.4 interegular-0.3.3 isort-6.0.0 lark-1.2.2 latex2sympy2-1.9.1 lm-format-enforcer-0.10.6 mistral-common-1.5.3 msgspec-0.19.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py-12.570.86 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 outlines-0.0.46 partial-json-parser-0.2.1.1.post5 pebble-5.1.0 prometheus-fastapi-instrumentator-7.0.2 pyairports-2.1.1 pycountry-24.6.1 python-dotenv-1.0.1 ray-2.42.1 ruff-0.9.7 search-and-learn-0.1.0 starlette-0.45.3 tiktoken-0.9.0 torch-2.4.0 torchvision-0.19.0 triton-3.0.0 uvicorn-0.34.0 uvloop-0.21.0 vllm-0.6.3 watchfiles-1.0.4 word2number-1.1 xformers-0.0.27.post2 xxhash-3.5.0\n"]}],"source":["!pip install -e '.[dev]'\n","# ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","# gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n","# torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.4.0 which is incompatible."]},{"cell_type":"code","source":["!python --version"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hNSg2lyYJA7S","executionInfo":{"status":"ok","timestamp":1740001359072,"user_tz":420,"elapsed":110,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"98895d33-b918-4220-8386-1dad61604de5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.11.11\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"8arKITR1zDin","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ff537b3f-ceee-432f-ca19-b53f030371a9","executionInfo":{"status":"ok","timestamp":1739391290030,"user_tz":420,"elapsed":3060,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: vllm in /usr/local/lib/python3.11/dist-packages (0.6.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from vllm) (5.9.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.26.4)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from vllm) (4.67.1)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from vllm) (9.0.0)\n","Requirement already satisfied: transformers>=4.45.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.48.2)\n","Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from vllm) (4.25.6)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from vllm) (3.11.12)\n","Requirement already satisfied: openai>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (1.61.1)\n","Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.11/dist-packages (from vllm) (0.34.0)\n","Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.10.6)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from vllm) (11.1.0)\n","Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.21.1)\n","Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (7.0.2)\n","Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.0)\n","Requirement already satisfied: lm-format-enforcer==0.10.6 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.6)\n","Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.46)\n","Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.11/dist-packages (from vllm) (4.12.2)\n","Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from vllm) (3.17.0)\n","Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.11/dist-packages (from vllm) (0.2.1.1.post5)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.11/dist-packages (from vllm) (24.0.1)\n","Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n","Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.10.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from vllm) (8.6.1)\n","Requirement already satisfied: mistral-common>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm) (1.5.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from vllm) (6.0.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from vllm) (0.8.0)\n","Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.42.1)\n","Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from vllm) (12.570.86)\n","Requirement already satisfied: torch==2.4.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (2.4.0)\n","Requirement already satisfied: torchvision==0.19 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.19.0)\n","Requirement already satisfied: xformers==0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.0.27.post2)\n","Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.11/dist-packages (from vllm) (0.115.8)\n","Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm) (0.3.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lm-format-enforcer==0.10.6->vllm) (24.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (2024.9.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (12.1.105)\n","Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->vllm) (3.0.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->vllm) (12.5.82)\n","Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.45.3)\n","Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (4.23.0)\n","Requirement already satisfied: opencv-python-headless>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mistral-common[opencv]>=1.4.4->vllm) (4.11.0.86)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm) (0.8.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.40.0->vllm) (1.3.1)\n","Requirement already satisfied: lark in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.2.2)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.1)\n","Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n","Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.61.0)\n","Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.36.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.2.0)\n","Requirement already satisfied: pycountry in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (24.6.1)\n","Requirement already satisfied: pyairports in /usr/local/lib/python3.11/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.1.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9->vllm) (2.27.2)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm) (8.1.8)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm) (1.1.0)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm) (1.3.2)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray>=2.9->vllm) (1.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->vllm) (2025.1.31)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.6.0->vllm) (2024.11.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.19.1->vllm) (0.28.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.45.0->vllm) (0.5.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (2.4.4)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (25.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->vllm) (1.18.3)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->vllm) (3.21.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n","Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (0.6.4)\n","Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (0.21.0)\n","Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (1.0.4)\n","Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]->vllm) (14.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.40.0->vllm) (1.0.7)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (2024.10.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral-common>=1.4.4->mistral-common[opencv]>=1.4.4->vllm) (0.22.3)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.70.16)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0->vllm) (3.0.2)\n","Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.44.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0->vllm) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm) (1.17.0)\n"]}],"source":["!pip install vllm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EUCgFC07x-lp","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1739391624146,"user_tz":420,"elapsed":147311,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"49d13f02-88cf-440c-ab45-58b179bd3481"},"outputs":[{"output_type":"stream","name":"stdout","text":["2025-02-12 20:18:01.103415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1739391481.125819    3919 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1739391481.132605    3919 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","/usr/local/lib/python3.11/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n","No module named 'vllm._version'\n","  from vllm.version import __version__ as VLLM_VERSION\n","config.json: 100% 877/877 [00:00<00:00, 4.72MB/s]\n","WARNING 02-12 20:18:22 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n","INFO 02-12 20:18:22 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.\n","INFO 02-12 20:18:22 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='meta-llama/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Llama-3.2-1B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n","tokenizer_config.json: 100% 54.5k/54.5k [00:00<00:00, 8.15MB/s]\n","tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 19.9MB/s]\n","special_tokens_map.json: 100% 296/296 [00:00<00:00, 1.82MB/s]\n","generation_config.json: 100% 189/189 [00:00<00:00, 1.34MB/s]\n","INFO 02-12 20:18:26 model_runner.py:1060] Starting to load model meta-llama/Llama-3.2-1B-Instruct...\n","INFO 02-12 20:18:26 weight_utils.py:243] Using model weights format ['*.safetensors']\n","model.safetensors: 100% 2.47G/2.47G [00:04<00:00, 591MB/s]\n","INFO 02-12 20:18:31 weight_utils.py:288] No model.safetensors.index.json found in remote.\n","Loading safetensors checkpoint shards: 100% 1/1 [00:00<00:00,  1.29it/s]\n","INFO 02-12 20:18:32 model_runner.py:1071] Loading model weights took 2.3185 GB\n","INFO 02-12 20:18:33 gpu_executor.py:122] # GPU blocks: 33062, # CPU blocks: 8192\n","INFO 02-12 20:18:33 gpu_executor.py:126] Maximum concurrency for 131072 tokens per request: 4.04x\n","INFO 02-12 20:18:35 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n","INFO 02-12 20:18:35 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","INFO 02-12 20:18:57 model_runner.py:1530] Graph capturing finished in 23 secs.\n","tokenizer_config.json: 100% 55.4k/55.4k [00:00<00:00, 172MB/s]\n","tokenizer.json: 100% 17.2M/17.2M [00:00<00:00, 41.3MB/s]\n","special_tokens_map.json: 100% 444/444 [00:00<00:00, 4.22MB/s]\n","config.json: 100% 896/896 [00:00<00:00, 6.73MB/s]\n","model.safetensors.index.json: 100% 23.9k/23.9k [00:00<00:00, 108MB/s]\n","Downloading shards:   0% 0/4 [00:00<?, ?it/s]\n","model-00001-of-00004.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n","model-00001-of-00004.safetensors:   0% 10.5M/4.98G [00:00<06:53, 12.0MB/s]\u001b[A\n","model-00001-of-00004.safetensors:   1% 62.9M/4.98G [00:01<01:02, 78.2MB/s]\u001b[A\n","model-00001-of-00004.safetensors:   3% 168M/4.98G [00:01<00:20, 230MB/s]  \u001b[A\n","model-00001-of-00004.safetensors:   5% 252M/4.98G [00:01<00:13, 340MB/s]\u001b[A\n","model-00001-of-00004.safetensors:   7% 346M/4.98G [00:01<00:09, 463MB/s]\u001b[A\n","model-00001-of-00004.safetensors:   9% 430M/4.98G [00:01<00:08, 522MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  10% 514M/4.98G [00:01<00:07, 571MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  12% 587M/4.98G [00:01<00:07, 591MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  13% 661M/4.98G [00:01<00:07, 606MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  15% 744M/4.98G [00:01<00:06, 665MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  17% 860M/4.98G [00:02<00:05, 792MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  20% 986M/4.98G [00:02<00:04, 890MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  22% 1.08G/4.98G [00:02<00:05, 744MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  24% 1.20G/4.98G [00:02<00:04, 829MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  27% 1.34G/4.98G [00:02<00:03, 952MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  30% 1.48G/4.98G [00:02<00:03, 1.05GB/s]\u001b[A\n","model-00001-of-00004.safetensors:  32% 1.59G/4.98G [00:02<00:03, 974MB/s] \u001b[A\n","model-00001-of-00004.safetensors:  34% 1.70G/4.98G [00:02<00:03, 895MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  36% 1.79G/4.98G [00:03<00:04, 667MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  38% 1.88G/4.98G [00:03<00:06, 479MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  40% 2.00G/4.98G [00:03<00:05, 555MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  42% 2.08G/4.98G [00:03<00:06, 473MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  43% 2.16G/4.98G [00:03<00:05, 535MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  45% 2.23G/4.98G [00:04<00:06, 393MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  47% 2.32G/4.98G [00:04<00:05, 449MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  48% 2.38G/4.98G [00:04<00:06, 386MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  49% 2.43G/4.98G [00:04<00:06, 387MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  50% 2.49G/4.98G [00:04<00:06, 388MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  51% 2.54G/4.98G [00:05<00:06, 387MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  52% 2.58G/4.98G [00:05<00:06, 344MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  53% 2.63G/4.98G [00:05<00:06, 366MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  55% 2.72G/4.98G [00:05<00:06, 339MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  56% 2.78G/4.98G [00:05<00:05, 378MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  57% 2.82G/4.98G [00:06<00:08, 243MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  58% 2.86G/4.98G [00:06<00:08, 242MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  58% 2.89G/4.98G [00:06<00:09, 227MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  59% 2.93G/4.98G [00:06<00:10, 188MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  60% 3.01G/4.98G [00:06<00:07, 276MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  61% 3.05G/4.98G [00:07<00:06, 291MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  63% 3.11G/4.98G [00:07<00:05, 354MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  64% 3.18G/4.98G [00:07<00:04, 400MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  66% 3.26G/4.98G [00:07<00:03, 501MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  68% 3.38G/4.98G [00:07<00:02, 656MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  70% 3.48G/4.98G [00:07<00:02, 582MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  71% 3.55G/4.98G [00:07<00:03, 473MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  73% 3.62G/4.98G [00:08<00:03, 395MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  75% 3.73G/4.98G [00:08<00:03, 369MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  78% 3.86G/4.98G [00:08<00:02, 499MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  79% 3.93G/4.98G [00:08<00:02, 378MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  81% 4.02G/4.98G [00:09<00:02, 379MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  83% 4.12G/4.98G [00:09<00:02, 357MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  84% 4.17G/4.98G [00:09<00:02, 293MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  87% 4.35G/4.98G [00:09<00:01, 494MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  89% 4.43G/4.98G [00:10<00:01, 413MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  92% 4.58G/4.98G [00:10<00:00, 476MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  93% 4.65G/4.98G [00:10<00:00, 467MB/s]\u001b[A\n","model-00001-of-00004.safetensors:  95% 4.73G/4.98G [00:10<00:00, 428MB/s]\u001b[A\n","model-00001-of-00004.safetensors: 100% 4.98G/4.98G [00:11<00:00, 441MB/s]\n","Downloading shards:  25% 1/4 [00:11<00:34, 11.47s/it]\n","model-00002-of-00004.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n","model-00002-of-00004.safetensors:   0% 10.5M/5.00G [00:01<08:01, 10.4MB/s]\u001b[A\n","model-00002-of-00004.safetensors:   0% 21.0M/5.00G [00:02<10:19, 8.04MB/s]\u001b[A\n","model-00002-of-00004.safetensors:   1% 62.9M/5.00G [00:02<02:30, 32.7MB/s]\u001b[A\n","model-00002-of-00004.safetensors:   2% 115M/5.00G [00:02<01:08, 71.2MB/s] \u001b[A\n","model-00002-of-00004.safetensors:   4% 178M/5.00G [00:02<00:37, 128MB/s] \u001b[A\n","model-00002-of-00004.safetensors:   6% 315M/5.00G [00:02<00:16, 282MB/s]\u001b[A\n","model-00002-of-00004.safetensors:   9% 451M/5.00G [00:03<00:10, 435MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  11% 566M/5.00G [00:03<00:08, 554MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  14% 703M/5.00G [00:03<00:06, 710MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  17% 849M/5.00G [00:03<00:04, 871MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  20% 975M/5.00G [00:03<00:04, 920MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  22% 1.09G/5.00G [00:03<00:04, 819MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  24% 1.20G/5.00G [00:03<00:04, 819MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  26% 1.29G/5.00G [00:04<00:05, 657MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  27% 1.37G/5.00G [00:04<00:08, 438MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  29% 1.44G/5.00G [00:04<00:11, 321MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  30% 1.49G/5.00G [00:05<00:11, 297MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  32% 1.60G/5.00G [00:05<00:08, 409MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  34% 1.69G/5.00G [00:05<00:06, 478MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  35% 1.76G/5.00G [00:05<00:06, 521MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  37% 1.86G/5.00G [00:05<00:05, 607MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  39% 1.94G/5.00G [00:05<00:04, 656MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  40% 2.02G/5.00G [00:05<00:06, 489MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  43% 2.13G/5.00G [00:06<00:06, 431MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  44% 2.19G/5.00G [00:06<00:06, 453MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  45% 2.25G/5.00G [00:06<00:09, 283MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  46% 2.31G/5.00G [00:06<00:09, 296MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  47% 2.35G/5.00G [00:07<00:11, 238MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  48% 2.39G/5.00G [00:07<00:10, 241MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  49% 2.46G/5.00G [00:07<00:08, 314MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  50% 2.51G/5.00G [00:07<00:09, 276MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  52% 2.58G/5.00G [00:07<00:09, 264MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  52% 2.62G/5.00G [00:08<00:08, 270MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  53% 2.65G/5.00G [00:08<00:11, 212MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  55% 2.74G/5.00G [00:08<00:07, 309MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  57% 2.87G/5.00G [00:08<00:04, 491MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  61% 3.07G/5.00G [00:08<00:02, 782MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  64% 3.18G/5.00G [00:08<00:02, 767MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  65% 3.27G/5.00G [00:08<00:02, 759MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  67% 3.37G/5.00G [00:09<00:02, 639MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  69% 3.45G/5.00G [00:09<00:02, 578MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  70% 3.52G/5.00G [00:09<00:03, 463MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  72% 3.60G/5.00G [00:09<00:03, 462MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  73% 3.65G/5.00G [00:10<00:03, 381MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  74% 3.70G/5.00G [00:10<00:04, 304MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  75% 3.74G/5.00G [00:10<00:04, 284MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  76% 3.81G/5.00G [00:10<00:03, 310MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  77% 3.86G/5.00G [00:10<00:03, 342MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  78% 3.90G/5.00G [00:10<00:03, 341MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  79% 3.94G/5.00G [00:11<00:03, 345MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  80% 4.00G/5.00G [00:11<00:03, 307MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  81% 4.04G/5.00G [00:11<00:03, 305MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  82% 4.08G/5.00G [00:11<00:04, 200MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  82% 4.12G/5.00G [00:12<00:04, 182MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  83% 4.15G/5.00G [00:12<00:04, 187MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  84% 4.18G/5.00G [00:12<00:05, 150MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  87% 4.33G/5.00G [00:12<00:01, 340MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  91% 4.56G/5.00G [00:12<00:00, 673MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  95% 4.74G/5.00G [00:12<00:00, 867MB/s]\u001b[A\n","model-00002-of-00004.safetensors:  97% 4.87G/5.00G [00:13<00:00, 769MB/s]\u001b[A\n","model-00002-of-00004.safetensors: 100% 5.00G/5.00G [00:13<00:00, 374MB/s]\n","Downloading shards:  50% 2/4 [00:25<00:25, 12.69s/it]\n","model-00003-of-00004.safetensors:   0% 0.00/4.92G [00:00<?, ?B/s]\u001b[A\n","model-00003-of-00004.safetensors:   0% 10.5M/4.92G [00:00<06:24, 12.8MB/s]\u001b[A\n","model-00003-of-00004.safetensors:   0% 21.0M/4.92G [00:00<03:25, 23.8MB/s]\u001b[A\n","model-00003-of-00004.safetensors:   1% 52.4M/4.92G [00:01<01:41, 47.7MB/s]\u001b[A\n","model-00003-of-00004.safetensors:   2% 115M/4.92G [00:01<00:39, 123MB/s]  \u001b[A\n","model-00003-of-00004.safetensors:   3% 168M/4.92G [00:01<00:25, 183MB/s]\u001b[A\n","model-00003-of-00004.safetensors:   5% 231M/4.92G [00:01<00:17, 261MB/s]\u001b[A\n","model-00003-of-00004.safetensors:   7% 336M/4.92G [00:01<00:10, 417MB/s]\u001b[A\n","model-00003-of-00004.safetensors:   9% 440M/4.92G [00:01<00:08, 534MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  12% 587M/4.92G [00:02<00:05, 726MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  14% 682M/4.92G [00:02<00:06, 649MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  16% 765M/4.92G [00:02<00:07, 525MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  17% 839M/4.92G [00:02<00:09, 411MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  18% 891M/4.92G [00:02<00:10, 371MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  19% 944M/4.92G [00:03<00:13, 303MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  20% 986M/4.92G [00:03<00:15, 260MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  21% 1.02G/4.92G [00:03<00:14, 265MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  22% 1.07G/4.92G [00:03<00:13, 295MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  23% 1.13G/4.92G [00:03<00:10, 349MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  24% 1.17G/4.92G [00:03<00:10, 362MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  25% 1.25G/4.92G [00:04<00:08, 427MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  27% 1.33G/4.92G [00:04<00:09, 391MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  28% 1.38G/4.92G [00:04<00:08, 413MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  29% 1.44G/4.92G [00:04<00:11, 314MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  30% 1.48G/4.92G [00:04<00:10, 317MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  31% 1.52G/4.92G [00:07<00:54, 62.7MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  34% 1.67G/4.92G [00:07<00:24, 134MB/s] \u001b[A\n","model-00003-of-00004.safetensors:  37% 1.84G/4.92G [00:07<00:13, 237MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  39% 1.93G/4.92G [00:07<00:10, 293MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  41% 2.03G/4.92G [00:07<00:07, 375MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  43% 2.13G/4.92G [00:07<00:06, 418MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  45% 2.21G/4.92G [00:07<00:05, 461MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  47% 2.30G/4.92G [00:08<00:05, 437MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  48% 2.37G/4.92G [00:08<00:06, 421MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  49% 2.43G/4.92G [00:08<00:06, 374MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  52% 2.54G/4.92G [00:08<00:05, 450MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  53% 2.60G/4.92G [00:08<00:05, 430MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  54% 2.65G/4.92G [00:08<00:05, 421MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  56% 2.74G/4.92G [00:09<00:04, 469MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  57% 2.82G/4.92G [00:11<00:20, 103MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  58% 2.86G/4.92G [00:11<00:18, 113MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  60% 2.97G/4.92G [00:11<00:11, 176MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  63% 3.11G/4.92G [00:11<00:06, 284MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  66% 3.24G/4.92G [00:11<00:04, 390MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  70% 3.43G/4.92G [00:11<00:02, 590MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  73% 3.58G/4.92G [00:11<00:01, 725MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  75% 3.70G/4.92G [00:12<00:01, 805MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  78% 3.83G/4.92G [00:12<00:01, 871MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  80% 3.95G/4.92G [00:14<00:06, 151MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  82% 4.05G/4.92G [00:14<00:04, 189MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  85% 4.16G/4.92G [00:14<00:03, 250MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  87% 4.26G/4.92G [00:14<00:02, 306MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  89% 4.37G/4.92G [00:15<00:01, 394MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  91% 4.49G/4.92G [00:15<00:00, 490MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  93% 4.59G/4.92G [00:15<00:00, 569MB/s]\u001b[A\n","model-00003-of-00004.safetensors:  96% 4.72G/4.92G [00:15<00:00, 683MB/s]\u001b[A\n","model-00003-of-00004.safetensors: 100% 4.92G/4.92G [00:19<00:00, 255MB/s]\n","Downloading shards:  75% 3/4 [00:44<00:15, 15.77s/it]\n","model-00004-of-00004.safetensors:   0% 0.00/1.17G [00:00<?, ?B/s]\u001b[A\n","model-00004-of-00004.safetensors:   0% 4.22M/1.17G [00:01<07:17, 2.66MB/s]\u001b[A\n","model-00004-of-00004.safetensors:   1% 14.7M/1.17G [00:03<04:05, 4.71MB/s]\u001b[A\n","model-00004-of-00004.safetensors:   7% 77.6M/1.17G [00:03<00:32, 34.0MB/s]\u001b[A\n","model-00004-of-00004.safetensors:   9% 109M/1.17G [00:03<00:21, 49.6MB/s] \u001b[A\n","model-00004-of-00004.safetensors:  12% 141M/1.17G [00:03<00:14, 70.5MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  16% 182M/1.17G [00:03<00:09, 104MB/s] \u001b[A\n","model-00004-of-00004.safetensors:  24% 277M/1.17G [00:03<00:04, 207MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  33% 382M/1.17G [00:04<00:02, 331MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  45% 529M/1.17G [00:04<00:01, 524MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  65% 759M/1.17G [00:04<00:00, 866MB/s]\u001b[A\n","model-00004-of-00004.safetensors:  83% 969M/1.17G [00:04<00:00, 1.11GB/s]\u001b[A\n","model-00004-of-00004.safetensors: 100% 1.17G/1.17G [00:07<00:00, 164MB/s]\n","Downloading shards: 100% 4/4 [00:51<00:00, 12.96s/it]\n","INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n","Loading checkpoint shards: 100% 4/4 [00:06<00:00,  1.59s/it]\n","generation_config.json: 100% 184/184 [00:00<00:00, 1.51MB/s]\n","README.md: 100% 412/412 [00:00<00:00, 3.85MB/s]\n","test.jsonl: 100% 447k/447k [00:00<00:00, 2.72MB/s]\n","Generating test split: 100% 500/500 [00:00<00:00, 23064.89 examples/s]\n","Parameter 'fn_kwargs'={'config': Config(approach='best_of_n', model_path='meta-llama/Llama-3.2-1B-Instruct', gpu_memory_utilization=0.5, prm_path='RLHFlow/Llama3.1-8B-PRM-Deepseek-Data', output_dir=None, num_proc=None, push_to_hub=False, hub_dataset_id=None, hub_dataset_private=False, overwrite_hub_revision=False, apply_voting=True, dataset_name='HuggingFaceH4/MATH-500', dataset_config=None, dataset_split='test', dataset_start=None, dataset_end=None, num_samples=10, system_prompt='Solve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.', custom_chat_template='{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', n=4, temperature=0.8, top_p=1.0, prm_batch_size=4, search_batch_size=25, seed=0, max_tokens=2048, agg_strategy='last', beam_width=4, num_iterations=40, lookahead=1, filter_duplicates=True, sort_completed=True), 'llm': <vllm.entrypoints.llm.LLM object at 0x79f8ec4513d0>, 'prm': <sal.models.reward_models.RLHFFlow object at 0x79f8ec59b310>} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","WARNING:datasets.fingerprint:Parameter 'fn_kwargs'={'config': Config(approach='best_of_n', model_path='meta-llama/Llama-3.2-1B-Instruct', gpu_memory_utilization=0.5, prm_path='RLHFlow/Llama3.1-8B-PRM-Deepseek-Data', output_dir=None, num_proc=None, push_to_hub=False, hub_dataset_id=None, hub_dataset_private=False, overwrite_hub_revision=False, apply_voting=True, dataset_name='HuggingFaceH4/MATH-500', dataset_config=None, dataset_split='test', dataset_start=None, dataset_end=None, num_samples=10, system_prompt='Solve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.', custom_chat_template='{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', n=4, temperature=0.8, top_p=1.0, prm_batch_size=4, search_batch_size=25, seed=0, max_tokens=2048, agg_strategy='last', beam_width=4, num_iterations=40, lookahead=1, filter_duplicates=True, sort_completed=True), 'llm': <vllm.entrypoints.llm.LLM object at 0x79f8ec4513d0>, 'prm': <sal.models.reward_models.RLHFFlow object at 0x79f8ec59b310>} of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","Running search:   0% 0/10 [00:15<?, ? examples/s]\n","[rank0]: Traceback (most recent call last):\n","[rank0]:   File \"/content/drive/My Drive/Colab Notebooks/packages/search-and-learn/scripts/test_time_compute.py\", line 74, in <module>\n","[rank0]:     main()\n","[rank0]:   File \"/content/drive/My Drive/Colab Notebooks/packages/search-and-learn/scripts/test_time_compute.py\", line 58, in main\n","[rank0]:     dataset = dataset.map(\n","[rank0]:               ^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\", line 560, in wrapper\n","[rank0]:     out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n","[rank0]:                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\", line 3073, in map\n","[rank0]:     for rank, done, content in Dataset._map_single(**dataset_kwargs):\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\", line 3476, in _map_single\n","[rank0]:     batch = apply_function_on_filtered_inputs(\n","[rank0]:             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/datasets/arrow_dataset.py\", line 3338, in apply_function_on_filtered_inputs\n","[rank0]:     processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n","[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/My Drive/Colab Notebooks/packages/search-and-learn/src/sal/search/best_of_n.py\", line 84, in best_of_n\n","[rank0]:     scores = prm.score(x[\"problem\"], completions)\n","[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/My Drive/Colab Notebooks/packages/search-and-learn/src/sal/models/reward_models.py\", line 164, in score\n","[rank0]:     return self._score_batched(questions, outputs, batch_size=batch_size)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/content/drive/My Drive/Colab Notebooks/packages/search-and-learn/src/sal/models/reward_models.py\", line 249, in _score_batched\n","[rank0]:     logits = self.model(inputs_batch).logits[:, :, self.candidate_tokens]\n","[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n","[rank0]:     return self._call_impl(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n","[rank0]:     return forward_call(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 847, in forward\n","[rank0]:     logits = self.lm_head(hidden_states[:, -num_logits_to_keep:, :])\n","[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n","[rank0]:     return self._call_impl(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n","[rank0]:     return forward_call(*args, **kwargs)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 117, in forward\n","[rank0]:     return F.linear(input, self.weight, self.bias)\n","[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","[rank0]: torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.12 GiB. GPU 0 has a total capacity of 39.56 GiB of which 818.88 MiB is free. Process 48346 has 38.74 GiB memory in use. Of the allocated memory 33.65 GiB is allocated by PyTorch, with 23.47 MiB allocated in private pools (e.g., CUDA Graphs), and 4.49 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"]}],"source":["!python scripts/test_time_compute.py ./recipes/Llama-3.2-1B-Instruct/best_of_n.yaml\n","\n","# with T4, I am getting the following error; L4 works fine.\n","#❯ ValueError: Bfloat16 is only supported on GPUs with compute capability of at least 8.0. Your Tesla T4 GPU has compute capability 7.5. You can use float16 instead by explicitly setting the`dtype` flag in CLI, for example: --dtype=half."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUDE6rSmQiru"},"outputs":[],"source":["import torch\n","import gc; gc.collect();torch.cuda.empty_cache();\n"]},{"cell_type":"code","source":["import copy\n","from tqdm import tqdm\n","from dataclasses import dataclass\n","\n","import torch\n","from vllm import LLM, SamplingParams\n","from sal.models.reward_models import RLHFFlow\n","\n","from sal.search.utils import Beam, build_conv, generate_k_steps, last\n","from sal.config import Config\n","from sal.models.reward_models import PRM\n","from sal.utils.score import aggregate_scores\n","\n","base_path = \"/content/drive/MyDrive/Colab Notebooks/packages/search-and-learn/\"\n","model_path = base_path + \"resources/Llama-3.2-1B-Instruct\"     # \"meta-llama/Llama-3.2-1B-Instruct\"\n","prm_path = base_path + \"resources/RLHFFlow/Llama3.1-8B-PRM-Deepseek-Data\"\n","\n","# import gc; gc.collect();torch.cuda.empty_cache();\n","\n","# print('#--- memory:', torch.cuda.memory_allocated(0)/(1024**3))\n","\n","\n"],"metadata":{"id":"jHUSnonS3SWA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740609136175,"user_tz":420,"elapsed":8868,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"f3d0e994-98a8-4669-8f53-0c0573da18bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:\n","No module named 'vllm._version'\n","  from vllm.version import __version__ as VLLM_VERSION\n"]}]},{"cell_type":"code","source":["llm = LLM(\n","    model=model_path,\n","    gpu_memory_utilization=0.5,  # Utilize 50% of GPU memory\n","    enable_prefix_caching=True,  # Optimize repeated prefix computations\n","    seed=42,  # Set seed for reproducibility\n",")\n"],"metadata":{"id":"gs_nPIXh4L8L","colab":{"base_uri":"https://localhost:8080/","height":243,"referenced_widgets":["aff7452b860a4fefabfdd878e5fab729","c881d6f3997c466e831432e49689a43d","a33de001a7a044c3aa400b3178f15ff7","150c565192124618b295bd3b515af960","826576c1cb3548b9bb7c05bb1f37f765","4804b05baa46425b94f1032097f721ed","c90edb1c121249579f204680429632e2","608abe2f22884ae0bfd6fafabe03e237","02246503a0d44cd8911a704da5205a03","6b0d9248ab8a4fcc83f4897edd9cd1aa","a457a608de594b868e63f34bfef2aa3a"]},"executionInfo":{"status":"ok","timestamp":1740609188509,"user_tz":420,"elapsed":40357,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"5fbd5d52-91ce-437b-ba77-d0ed9e18ad40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING 02-26 22:32:37 arg_utils.py:953] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.\n","INFO 02-26 22:32:37 config.py:1005] Chunked prefill is enabled with max_num_batched_tokens=512.\n","INFO 02-26 22:32:37 llm_engine.py:237] Initializing an LLM engine (vdev) with config: model='/content/drive/MyDrive/Colab Notebooks/packages/search-and-learn/resources/Llama-3.2-1B-Instruct', speculative_config=None, tokenizer='/content/drive/MyDrive/Colab Notebooks/packages/search-and-learn/resources/Llama-3.2-1B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=42, served_model_name=/content/drive/MyDrive/Colab Notebooks/packages/search-and-learn/resources/Llama-3.2-1B-Instruct, use_v2_block_manager=True, num_scheduler_steps=1, chunked_prefill_enabled=True multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n","INFO 02-26 22:32:39 model_runner.py:1060] Starting to load model /content/drive/MyDrive/Colab Notebooks/packages/search-and-learn/resources/Llama-3.2-1B-Instruct...\n"]},{"output_type":"display_data","data":{"text/plain":["Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aff7452b860a4fefabfdd878e5fab729"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 02-26 22:32:42 model_runner.py:1071] Loading model weights took 2.3185 GB\n","INFO 02-26 22:32:42 gpu_executor.py:122] # GPU blocks: 33062, # CPU blocks: 8192\n","INFO 02-26 22:32:42 gpu_executor.py:126] Maximum concurrency for 131072 tokens per request: 4.04x\n","INFO 02-26 22:32:44 model_runner.py:1402] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n","INFO 02-26 22:32:44 model_runner.py:1406] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n","INFO 02-26 22:33:07 model_runner.py:1530] Graph capturing finished in 23 secs.\n"]}]},{"cell_type":"code","source":["prm = RLHFFlow(prm_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["68ed973a465042f59f8e18e5a5369653","9b7c7ebbdb4845828e30cdfceb5e6d3b","b9dc23f2b59544a09abdb8920610e6d7","0c4d8271dee94e04af7b49cc8fa8ba1f","4c08e1be2f2d48a9802dd34858079f29","9f6004155b8945bc91c56f84946be216","74c04b0fc3fe4a1f97d17c2d2f31836d","e7c6a5dddd894ba68deb88b7cc9cd0f8","ae61e060a981495480e0bd4db2f654ca","37cea44a02b24cbd8e35c4f48bc4691b","e98fb062be9b422e8e32894fdb3d2f69"]},"id":"I_bUmOpGlguE","executionInfo":{"status":"ok","timestamp":1740609196406,"user_tz":420,"elapsed":7824,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"eea8d92d-8bc9-4a55-9810-bb12f8f9e229"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68ed973a465042f59f8e18e5a5369653"}},"metadata":{}}]},{"cell_type":"code","source":["import ipdb"],"metadata":{"id":"suhr8UKzn-z3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["question_text = \"Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$\"\n","input_batch = {\"problem\": [question_text]}"],"metadata":{"id":"JrmKM8vzxz5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sal.search.utils import Beam, build_conv, generate_k_steps, last\n"],"metadata":{"id":"ePaS05SPR3Gb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = Config()\n","config.agg_strategy = 'last'\n","config.n = 2\n","config.lookahead = 2\n","config.num_iterations = 10\n","\n","@dataclass\n","class GenResult:\n","    index: int\n","    initial_prompt: str\n","    first_step_text: str\n","    first_step_stop_reason: str\n","    lookahead_text: str\n","    stop_reason: str | None\n","\n","def generate_k_steps(\n","    templated_convs,\n","    lookahead_steps: int,\n","    llm: LLM,\n","    sampling_params: SamplingParams,\n","    beam_width: int,\n",") -> list[Beam]:\n","    '''\n","\n","    '''\n","\n","    gen_results = []\n","    for i, text in enumerate(templated_convs):\n","        for j in range(beam_width):\n","            gen_result = GenResult(\n","                index=i,\n","                initial_prompt=text,\n","                first_step_text=\"\",\n","                lookahead_text=\"\",\n","                stop_reason=None,\n","                first_step_stop_reason=None,\n","            )\n","            gen_results.append(gen_result)\n","\n","\n","    gen_sampling_params = copy.deepcopy(sampling_params)\n","\n","    for i in range(lookahead_steps + 1):\n","        if i == 1:\n","            gen_sampling_params.temperature = 0.0  # greedy for the rest of the steps\n","        # get all generations that did not finish with eos\n","        # print(gen_results)\n","        current_gen = [\n","            gen_results[i]\n","            for i in range(len(gen_results))\n","            if gen_results[i].stop_reason != \"EOS\"\n","        ]\n","        gen_prompts = [\n","            gen_result.initial_prompt + gen_result.lookahead_text\n","            for gen_result in current_gen\n","        ]\n","\n","\n","        llm_outputs = llm.generate(gen_prompts, gen_sampling_params, use_tqdm=False)\n","        for gen_result, output in zip(current_gen, llm_outputs):\n","            gen_text = output.outputs[0].text\n","            # print(gen_text)\n","            # stop\n","            if i == 0:\n","                gen_result.first_step_text = gen_text\n","                gen_result.first_step_stop_reason = output.outputs[0].stop_reason\n","                if gen_result.first_step_stop_reason is None:\n","                    gen_result.first_step_stop_reason = \"EOS\"\n","\n","            gen_result.lookahead_text = gen_result.lookahead_text + gen_text\n","            gen_result.stop_reason = output.outputs[0].stop_reason\n","            if gen_result.stop_reason is None:\n","                gen_result.stop_reason = \"EOS\"\n","\n","    outputs: list[Beam] = []\n","\n","    counter = 0\n","    for i, text in enumerate(templated_convs):\n","        next_texts = []\n","        stop_reasons = []\n","        lookahead_texts = []\n","        for j in range(beam_width):\n","            gen_result = gen_results[counter]\n","            next_texts.append(gen_result.first_step_text)\n","            lookahead_texts.append(gen_result.lookahead_text)\n","            stop_reasons.append(gen_result.first_step_stop_reason)\n","            counter += 1\n","\n","        beam_result = Beam(\n","            prompt=text,\n","            index=i,\n","            current_text=\"\",\n","            next_texts=next_texts,\n","            lookahead_texts=lookahead_texts,\n","            stop_reasons=stop_reasons,\n","            best_scores=[0.0],\n","            all_scores=[],\n","            previous_text=None,\n","            pruned=False,\n","            history=[],\n","        )\n","        outputs.append(beam_result)\n","\n","    return outputs\n","\n","def _beam_search(batch_of_prompts, config: Config, llm: LLM, prm: PRM) -> list[Beam]:\n","    '''\n","    _beam_search: private function, the core beam search algorithm\n","    - batch_of_prompts:\n","        a list of input prompts [\"What is the capital of USA\", \"What is the length of the Nile River?\"]\n","        config: a Config object with settings\n","    '''\n","\n","    sampling_params = SamplingParams(temperature=config.temperature,\n","                                    max_tokens=config.max_tokens,\n","                                    top_p=config.top_p,\n","                                    stop=[\"\\n\\n\"],\n","                                    include_stop_str_in_output=True,\n","                                    n=1)\n","\n","    # ipdb.set_trace()\n","    beams: list[Beam] = []\n","    # create config.n beams for each prompt in the batch.\n","    for prompt in batch_of_prompts:\n","        for i in range(config.n):\n","            beams.append(\n","                Beam(\n","                    prompt=prompt,\n","                    index=i,\n","                    current_text=\"\",\n","                    next_texts=None,\n","                    lookahead_texts=None,\n","                    pruned=False,           # flag to track whether beam is active\n","                    completed=False,        # flag to track completion\n","                    stop_reasons=None,\n","                    history=[],             # list of generated text segments\n","                    best_scores=[],\n","                    all_scores=[],\n","                    previous_text=None,\n","                    completion_tokens=0,    # token counts\n","                )\n","            )\n","\n","    completed_beams: list[Beam] = []\n","\n","    for i in range(config.num_iterations):\n","        print(f\"\\n-> i = {i}\")\n","        # filters beams to get only active (non-pruned) ones\n","        # first iteration i==0: uses all intial beams\n","        if i == 0:\n","            active_beams = [b for b in beams if not b.pruned]\n","        else:\n","            active_beams = [b for b in active_beams if not b.pruned]\n","\n","        # duplicate active beams to ensure that we have config.n beams per iteration\n","        # when do we have to duplicate active beams?\n","        if len(active_beams) != config.n:\n","            repeats = (config.n // len(active_beams)) + 1\n","            # logger.debug(\n","            #     f\"Extending active_beams with {repeats} repetitions to reach size {config.n}\"\n","            # )\n","            extended_active_beams = [\n","                copy.deepcopy(b) for b in (active_beams * repeats)[: config.n]\n","            ]\n","            active_beams = extended_active_beams\n","            if len(active_beams) != config.n:\n","                raise ValueError(\n","                    f\"Expected {config.n} active beams, but got {len(active_beams)}\"\n","                )\n","\n","        # adjust sampling_params for the last iterations\n","        # one difference from the general sampling_params\n","        # remove the parameter stop strings\n","        if i == config.num_iterations - 1:\n","            # Last iteration, generate to EOS\n","            sampling_params = SamplingParams(\n","                temperature=config.temperature,\n","                max_tokens=config.max_tokens,\n","                top_p=config.top_p,\n","                n=1,\n","            )\n","\n","        # builds conversation contexts for each active beam\n","        convs = [\n","            build_conv(b.prompt, b.current_text, config.system_prompt)\n","            for b in active_beams\n","        ]\n","\n","        # set flags for conversation formatting\n","        continue_final_message = i > 0      # True after the first iteration to append to existing text.\n","        add_generation_prompt = i == 0      # True only on the first iteration to start generation.\n","\n","        # override the default chat template if a custom one is provided.\n","        tokenizer = llm.get_tokenizer()\n","        if config.custom_chat_template is not None:\n","            tokenizer.chat_template = config.custom_chat_template\n","\n","        # ipdb.set_trace()\n","        templated_convs = tokenizer.apply_chat_template(\n","            convs,\n","            add_generation_prompt=add_generation_prompt,\n","            continue_final_message=continue_final_message,\n","            tokenize=False          # return strings, not token IDs, e.g.,\n","                                    # [[128006, 9125, 128007, 271, 38766]?\n","        )\n","        print(templated_convs)\n","        stop\n","\n","        # set number of lookahead steps, 0 (no lookahead) on the last iteration\n","        lookahead = 0 if i == config.num_iterations - 1 else config.lookahead\n","\n","        #\n","        gen_results = generate_k_steps(\n","            templated_convs, lookahead, llm, sampling_params, 1\n","        )\n","\n","        prompts, completions = [], []\n","\n","        # print(\"beams\")\n","        for beam, gen_result in zip(active_beams, gen_results, strict=True):\n","            # print(beam)\n","            # print(gen_result)\n","            beam.next_texts = gen_result.next_texts\n","            beam.stop_reasons = gen_result.stop_reasons\n","            beam.lookahead_texts = gen_result.lookahead_texts\n","            beam.completion_tokens += gen_result.completion_tokens\n","            beam.current_text += beam.next_texts[0]\n","            beam.history.append(beam.next_texts[0])\n","            # print()\n","            # print(\"beam.next_texts\")\n","            # print(gen_result.next_texts)\n","            # print(\"beam.stop_reasons\")\n","            # print(gen_result.stop_reasons)\n","            # print(\"beam.lookahead_texts\")\n","            # print(gen_result.lookahead_texts)\n","            # print(\"beam.current_text\")\n","            # print(beam.next_texts[0])\n","            # print(beam.current_text)\n","            # print(\"beam.completion_tokens\")\n","            # print(gen_result.completion_tokens)\n","            # print(beam.completion_tokens)\n","\n","            if (\n","                beam.stop_reasons[0] == \"EOS\"\n","                or beam.stop_reasons[0] == \"length\"\n","                or beam.next_texts[0] == \"\"\n","            ):\n","                beam.completed = True\n","                completed_beams.append(beam)\n","            prompts.append(beam.prompt)\n","            completions.append([beam.current_text])\n","\n","        # print(prompts)\n","        # print()\n","        # print(\"completions\")\n","        # print(completions)\n","\n","        scores = prm.score(prompts, completions)\n","        agg_scores = [\n","            [aggregate_scores(s, config.agg_strategy) for s in score]\n","            for score in scores\n","        ]\n","        # print(\"scores\")\n","        # print(scores)\n","        # print(agg_scores)\n","\n","        for beam, score in zip(active_beams, scores, strict=True):\n","            beam.all_scores = score[0]\n","\n","        # filter active_beams and agg_scores for beams that are completed\n","        agg_scores = [\n","            agg_scores[i] for i, b in enumerate(active_beams) if not b.completed\n","        ]\n","        active_beams = [b for b in active_beams if not b.completed]\n","\n","        # early stopping if all beams are completed\n","        if len(active_beams) == 0:\n","            break\n","\n","        # filter duplicate active beams\n","        if config.filter_duplicates:\n","            # Create a dictionary to filter duplicates and retain order\n","            unique_beam_dict = {}\n","            for i, b in enumerate(active_beams):\n","                if b.current_text not in unique_beam_dict:\n","                    unique_beam_dict[b.current_text] = (\n","                        i  # Map the unique text to its index\n","                    )\n","            active_beams = [active_beams[i] for i in unique_beam_dict.values()]\n","            agg_scores = [agg_scores[i] for i in unique_beam_dict.values()]\n","\n","        # get indices for top (config.n / config.beam_width) completions\n","        top_indices = np.argsort(np.array(agg_scores).flatten())[\n","            -(config.n // config.beam_width) :\n","        ]\n","\n","        for idx, beam in enumerate(active_beams):\n","            if idx not in top_indices:\n","                beam.pruned = True\n","\n","    # filter completed beams for those with top config.n scores\n","    if config.sort_completed:\n","        completed_beams = sorted(\n","            completed_beams,\n","            key=lambda b: aggregate_scores(b.all_scores, config.agg_strategy),\n","            reverse=True,\n","        )[: config.n]\n","    else:\n","        completed_beams = completed_beams[: config.n]\n","\n","    if len(completed_beams) != config.n:\n","        # if we don't have enough completed_beams, duplicate until we reach config.n\n","        repeats = (config.n // len(completed_beams)) + 1\n","        logger.debug(\n","            f\"Extending completed_beams with {repeats} repetitions to reach size {config.n}\"\n","        )\n","        extended_completed_beams = [\n","            copy.deepcopy(b) for b in (completed_beams * repeats)[: config.n]\n","        ]\n","        completed_beams = extended_completed_beams\n","\n","    return completed_beams\n","\n","\n","\n","beam_results = _beam_search(input_batch['problem'], config, llm, prm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"LG4u8ie_ygVi","executionInfo":{"status":"error","timestamp":1740609990647,"user_tz":420,"elapsed":63,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"4ae47c2a-1cfc-4782-8a8a-47cdfba21ffc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","-> i = 0\n","['<|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Feb 2025\\n\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nConvert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\\\le \\theta < 2 \\\\pi.$<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n', '<|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 Feb 2025\\n\\nSolve the following math problem efficiently and clearly:\\n\\n- For simple problems (2 steps or fewer):\\nProvide a concise solution with minimal explanation.\\n\\n- For complex problems (3 steps or more):\\nUse this step-by-step format:\\n\\n## Step 1: [Concise description]\\n[Brief explanation and calculations]\\n\\n## Step 2: [Concise description]\\n[Brief explanation and calculations]\\n\\n...\\n\\nRegardless of the approach, always conclude with:\\n\\nTherefore, the final answer is: $\\\\boxed{answer}$. I hope it is correct.\\n\\nWhere [answer] is just the final number or expression that solves the problem.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nConvert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\\\le \\theta < 2 \\\\pi.$<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n']\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'stop' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-755bca7554db>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m \u001b[0mbeam_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_beam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'problem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-755bca7554db>\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(batch_of_prompts, config, llm, prm)\u001b[0m\n\u001b[1;32m    205\u001b[0m         )\n\u001b[1;32m    206\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplated_convs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;31m# set number of lookahead steps, 0 (no lookahead) on the last iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"]}]},{"cell_type":"code","source":["config = Config()\n","config.n = 10\n","config.agg_strategy = 'last'"],"metadata":{"id":"yO4yfkwdZgg9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","def _maxk_sequence(batch_of_prompts, config: Config, llm: LLM, prm: PRM) -> list[Beam]:\n","    '''\n","    '''\n","\n","    sampling_params = SamplingParams(temperature=config.temperature,\n","                                    max_tokens=config.max_tokens,\n","                                    top_p=config.top_p,\n","                                    # stop=[\"\\n\\n\"],\n","                                    # include_stop_str_in_output=True,\n","                                    n=1)\n","\n","    convs = [\n","        [\n","            {\"role\": \"system\", \"content\": config.system_prompt},\n","            {\"role\": \"user\", \"content\": prompt},\n","        ]\n","        for prompt in batch_of_prompts * config.n\n","    ]\n","    tokenizer = llm.get_tokenizer()\n","    if config.custom_chat_template is not None:\n","        tokenizer.chat_template = config.custom_chat_template\n","    templated_convs = tokenizer.apply_chat_template(\n","        convs,\n","        tokenize=False,\n","    )\n","\n","    # Initialize empty lists for completions and completion tokens\n","    completions = [[] for _ in range(len(batch_of_prompts))]\n","    completion_tokens = [[] for _ in range(len(batch_of_prompts))]\n","\n","    sampling_params = SamplingParams(\n","        temperature=config.temperature,\n","        max_tokens=config.max_tokens,\n","        top_p=config.top_p,\n","        n=1,  # Since we've already duplicated the prompt_token_ids, we only need to generate 1 completion per prompt\n","    )\n","\n","    responses = llm.generate(\n","        templated_convs,\n","        sampling_params=sampling_params,\n","        use_tqdm=False,\n","    )\n","    if len(responses) != len(batch_of_prompts) * config.n:\n","        raise ValueError(\n","            f\"Generated {len(responses)} responses instead of {len(batch_of_prompts * config.n)}\"\n","        )\n","\n","    for i in range(len(completions)):\n","        completions[i] = [\n","            output.text\n","            for r in responses[i * config.n : (i + 1) * config.n]\n","            for output in r.outputs\n","        ]\n","        completion_tokens[i] = [\n","            len(output.token_ids)\n","            for r in responses[i * config.n : (i + 1) * config.n]\n","            for output in r.outputs\n","        ]\n","\n","    # Check we generated the correct number of completions for each prompt\n","    for c in completions:\n","        if len(c) != config.n:\n","            raise ValueError(f\"Generated {len(c)} completions instead of {config.n}\")\n","\n","    scores = prm.score(batch_of_prompts, completions)\n","    agg_scores = [\n","        [aggregate_scores(s, config.agg_strategy) for s in score] for score in scores\n","    ]\n","    # print(scores)\n","    # print(agg_scores)\n","    print(len(agg_scores[0]))\n","\n","    max_score = 0\n","    max_score_arr = np.zeros(config.n)\n","    for i, score in enumerate(agg_scores[0]):\n","        if score > max_score:\n","            max_score = score\n","        max_score_arr[i] = max_score\n","\n","    return max_score_arr\n","\n","\n"],"metadata":{"id":"d-8-0hHeQ_uF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = Config()\n","config.n = 10\n","config.agg_strategy = 'last'\n","\n","num_trials = 30\n","# trial_max_score_arr = np.zeros(config.n)\n","trial_max_score_arr = []\n","for trial_id in range(num_trials):\n","    trial_max_score_arr.append(_maxk_sequence(input_batch['problem'], config, llm=llm, prm=prm))\n","\n","# trial_max_score_arr /= num_trials"],"metadata":{"id":"V0TTCD6sShB8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1740609423231,"user_tz":420,"elapsed":102985,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"c1f1d25e-d0e0-4c88-e762-c85849e5c74d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n","1\n"]}]},{"cell_type":"code","source":["# config.n = 20\n","# res = res.reshape(num_trials, )\n","# max_score = 0\n","#     max_score_arr = np.zeros(config.n)\n","#     for i, score in enumerate(agg_scores[0]):\n","#         if score > max_score:\n","#             max_score = score\n","#         max_score_arr[i] = max_score\n","\n","#     return max_score_arr"],"metadata":{"id":"S87zH1EEYEWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","\n","xrange = np.arange(1,config.n+1)\n","for i in range(num_trials):\n","    plt.plot(xrange, trial_max_score_arr[i], alpha=0.3, color='k')\n","plt.xticks(xrange)\n","plt.show()"],"metadata":{"id":"jD_bGMb0RC7G","executionInfo":{"status":"ok","timestamp":1740609488460,"user_tz":420,"elapsed":113,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"colab":{"base_uri":"https://localhost:8080/","height":430},"outputId":"30cece8d-be94-4018-9758-303ba30136b4"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["xrange = np.arange(1,config.n+1)\n","plt.plot(xrange, trial_max_score_arr)\n","plt.xticks(xrange)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"xmwL3HmwQ9GX","executionInfo":{"status":"ok","timestamp":1740607357787,"user_tz":420,"elapsed":118,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"0ccdd83c-b2e7-40d5-eb35-7520a8b3fc5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOHBJREFUeJzt3Xl4VPXdx/3PLJlsJAGSkBAIQUChUAgKGkG6WPMQ0CeitQqICHHphTdYIS0qyqL1Vkp7S7FKRS241oreRatio5gK6iOLBqlyiwhCCUsSSCDbBLLNef6AmRCJJJM5syS8X9d1LpKTM9/5TWScD7/zWyyGYRgCAAAIYdZgNwAAAKA1BBYAABDyCCwAACDkEVgAAEDII7AAAICQR2ABAAAhj8ACAABCHoEFAACEPHuwG2AGl8ulQ4cOKSYmRhaLJdjNAQAAbWAYhqqqqpSSkiKr9ex9KJ0isBw6dEipqanBbgYAAGiH/fv3q3fv3me9plMElpiYGEknX3BsbGyQWwMAANqisrJSqampns/xs+kUgcV9Gyg2NpbAAgBAB9OW4RwMugUAACGPwAIAAEIegQUAAIQ8AgsAAAh5BBYAABDyCCwAACDkEVgAAEDII7AAAICQR2ABAAAhz+vA8uGHHyo7O1spKSmyWCx64403Wn3M+vXrddFFFyk8PFwDBgzQc889d8Y1y5cvV9++fRUREaGMjAxt2bLF26YBAIBOyuvA4nQ6lZ6eruXLl7fp+r179+qqq67S5Zdfrm3btmn27Nm67bbb9O6773quWb16tXJzc7Vo0SJt3bpV6enpysrK0uHDh71tHgAA6IQshmEY7X6wxaLXX39d11xzzfdec88992jt2rXavn2759ykSZNUXl6uvLw8SVJGRoYuvvhiPfHEE5Ikl8ul1NRU3Xnnnbr33ntbbUdlZaXi4uJUUVHBXkIAAHQQ3nx++33zw40bNyozM7PZuaysLM2ePVuSVFdXp4KCAs2bN8/zc6vVqszMTG3cuLHFmrW1taqtrfV8X1lZaX7DcU4yDEP1jYYaXC7VNxqqb3Sp4dSfJ49T51zNzzWc/rXLpfoGQw2udv9boNMzZMgwTv6+XYbkMk5+3+xPnfa9q+l7l+dx7mtb+F787gGz2a0W3X/V4OA9v7+foLi4WElJSc3OJSUlqbKyUsePH9exY8fU2NjY4jVff/11izUXL16sBx980G9tRuhpdBk6Xt+o43Unj5r6BtXUnf59o47XnTp36rqaU8fxugYdr2/0XH/6NfWNLtWdFkoIGQDQMofd2rkDiz/MmzdPubm5nu8rKyuVmpoaxBadWxoaXTpWU68yZ60qjzeotqFRdQ2uk0ejS7UNJ4+604/GRtXWn/y5+1xto+u0c41Njz/tuhOngkZtgytor9dutchusyjMZj11WGS3nvwzzGaV3WaVw2aR3WaV3WqRw37yT5vVqjbsmH7Oslokq8Uiq8Uieb4++afF/adOnbeevAVttUgWnfrz1GNPfu1+XNP3AMxlswZ3YrHfA0tycrJKSkqanSspKVFsbKwiIyNls9lks9lavCY5ObnFmuHh4QoPD/dbm881LpehiuMnA0hpdZ2OOutUVn3a185alVXXqezU+fLj9Wr/yCffRTlsigyzKdJhO/m1w66oU99HOmyKCms6H+n52vadx538mcPeFDxOhg+LwqxWhdmbQomFTz8ACDq/B5ZRo0bpnXfeaXZu3bp1GjVqlCTJ4XBoxIgRys/P9wzedblcys/P16xZs/zdvE7N5TL05cEKFVWc8ISQMmdT8DjqrFNpdZ2O1dSp0ctbIRaL1C3KobjIMIXbrXLYrXLYrAoPO/mnw26Vw25rdq7l606GBs/P7FaF25q+jgyzKeJU6Ihy2BURZiVAAMA5yOvAUl1drd27d3u+37t3r7Zt26bu3burT58+mjdvng4ePKgXXnhBkjRjxgw98cQTuvvuu3XLLbfoX//6l1599VWtXbvWUyM3N1fTpk3TyJEjdckll2jZsmVyOp3Kyckx4SWeu/68frf+571v2nx9bIRdCV3C1T3aofguDsV3CVd8tEPx0Q517xKuhOiT57pHO9QtKkx2G+sOAgACw+vA8tlnn+nyyy/3fO8eSzJt2jQ999xzKioqUmFhoefn5513ntauXas5c+boscceU+/evfWXv/xFWVlZnmsmTpyoI0eOaOHChSouLtbw4cOVl5d3xkBctF1dg0vPfbJPkjS4Z6xSukYoPjpc8V0c6h7tUEKX5l93i3LIYSeAAABCk0/rsIQK1mE501v/PqQ7//a5esSE6/+792cKozcEABBivPn85lOsk3pp08nelUmX9CGsAAA6PD7JOqFvSqq0ee9R2awWTb6E6d4AgI6PwNIJ/fVU70rmD3qoZ1xkkFsDAIDvCCydjLO2QWu2HpQk3XRpWpBbAwCAOQgsncw/th1SVW2D+sZH6bL+CcFuDgAApiCwdCKGYXgG2950aZqsVhZYAwB0DgSWTmRrYbm+KqpUuN2qX4zoHezmAABgGgJLJ+IebJudnqKuUY4gtwYAAPMQWDqJo846vf1lkSQG2wIAOh8CSyfx2mf7Vdfg0g97xSq9d1ywmwMAgKkILJ2Ay2Xor5tP7t809dI0djMGAHQ6BJZO4MNdR1R4tEYxEXZlp6cEuzkAAJiOwNIJvLTpZO/KL0b0VpTD6w24AQAIeQSWDu5g+XH96+sSSdKUDAbbAgA6JwJLB/e3zYVyGdKofvEa0KNLsJsDAIBfEFg6sLoGl175dL8kaeooelcAAJ0XgaUDe++rYpVW16pHTLj+n8FJwW4OAAB+Q2DpwF7ceHJl20kXpyrMxn9KAEDnxadcB7WrpEqb9x6VzWrR5Iw+wW4OAAB+RWDpoNy7Ml8xqId6xkUGuTUAAPgXgaUDctY2aM3Wg5IYbAsAODcQWDqgN/99SFW1DeobH6XL+icEuzkAAPgdgaWDMQzDM9h2SkaarFb2DQIAdH4Elg7m8/3l+qqoUuF2q34xonewmwMAQEAQWDqYl071rvy/w1LULdoR5NYAABAYBJYO5JizTm9/WSSJwbYAgHMLgaUDea1gv+oaXPphr1il944LdnMAAAgYAksH4XIZ+uvmQknSTRlpslgYbAsAOHcQWDqIj3aXal9ZjWIi7Lp6eEqwmwMAQEARWDoI91Tm6y7qrSiHPcitAQAgsAgsHcDB8uP619clkqSbLmXfIADAuYfA0gG8sqVQLkMa1S9eA3rEBLs5AAAEHIElxNU1uPS3LfslSTddylRmAMC5icAS4t77qlil1bVKjAnX2CFJwW4OAABBQWAJcS9tOjnYdvLFqQqz8Z8LAHBu4hMwhO0qqdKmPUdltUiTLmGwLQDg3EVgCWHuheIyf5CklK6RQW4NAADBQ2AJUc7aBv294IAkBtsCAEBgCVFv/vuQqmob1Dc+SmMGJAS7OQAABBWBJQQZhuFZ2XZKRpqsVvYNAgCc2wgsIejz/eX6qqhSDrtVvxjRO9jNAQAg6AgsIcg9lTl7WIq6RTuC3BoAAIKPwBJijjnr9PYXRZLYNwgAADcCS4h5rWC/6hpcGpISq+GpXYPdHAAAQgKBJYS4XIZn7ZWpl6bJYmGwLQAAEoElpHy0u1T7ymoUE2HX1cNTgt0cAABCBoElhLgH2153UW9FOexBbg0AAKGDwBIiDpYfV/6OEkkMtgUA4LsILCHilS2FchnSpf26a0CPmGA3BwCAkEJgCQF1DS698ul+SdLUS/sGtzEAAIQgAksIeO+rYh2pqlViTLjGDkkKdnMAAAg5BJYQ4B5sO/niVIXZ+E8CAMB38ekYZLtKqrRpz1FZLdKkSxhsCwBAS9oVWJYvX66+ffsqIiJCGRkZ2rJly/deW19fr9/+9rfq37+/IiIilJ6erry8vGbXPPDAA7JYLM2OQYMGtadpHY57obgrfpCklK6RQW4NAAChyevAsnr1auXm5mrRokXaunWr0tPTlZWVpcOHD7d4/fz58/XUU0/p8ccf11dffaUZM2bo2muv1eeff97suiFDhqioqMhzfPzxx+17RR1ITV2D/l5wQNLJlW0BAEDLvA4sS5cu1e23366cnBwNHjxYK1asUFRUlFatWtXi9S+++KLuu+8+XXnllerXr5/uuOMOXXnllXr00UebXWe325WcnOw5EhIS2veKOpDNe46qqrZBvbtFasyAzv96AQBoL68CS11dnQoKCpSZmdlUwGpVZmamNm7c2OJjamtrFRER0excZGTkGT0ou3btUkpKivr166cpU6aosLDQm6Z1SIerTkiSLkiKkdXKvkEAAHwfrwJLaWmpGhsblZTUfOptUlKSiouLW3xMVlaWli5dql27dsnlcmndunVas2aNioqKPNdkZGToueeeU15enp588knt3btXP/rRj1RVVdVizdraWlVWVjY7OqLS6jpJUny0I8gtAQAgtPl9ltBjjz2m888/X4MGDZLD4dCsWbOUk5Mjq7XpqcePH6/rr79ew4YNU1ZWlt555x2Vl5fr1VdfbbHm4sWLFRcX5zlSU1P9/TL8orS6VpIU3yU8yC0BACC0eRVYEhISZLPZVFJS0ux8SUmJkpOTW3xMYmKi3njjDTmdTu3bt09ff/21unTpon79+n3v83Tt2lUXXHCBdu/e3eLP582bp4qKCs+xf/9+b15GyCg71cOS0IUeFgAAzsarwOJwODRixAjl5+d7zrlcLuXn52vUqFFnfWxERIR69eqlhoYG/f3vf9eECRO+99rq6mp9++236tmzZ4s/Dw8PV2xsbLOjIypzuntYCCwAAJyN17eEcnNz9cwzz+j555/Xjh07dMcdd8jpdConJ0eSdPPNN2vevHme6zdv3qw1a9Zoz549+uijjzRu3Di5XC7dfffdnmt+85vfaMOGDfrPf/6jTz75RNdee61sNpsmT55swksMXU09LNwSAgDgbOzePmDixIk6cuSIFi5cqOLiYg0fPlx5eXmegbiFhYXNxqecOHFC8+fP1549e9SlSxddeeWVevHFF9W1a1fPNQcOHNDkyZNVVlamxMREjRkzRps2bVJiYqLvrzCENQ26JbAAAHA2FsMwjGA3wleVlZWKi4tTRUVFh7k91OgydP7978hlSFvuu0I9YiNafxAAAJ2IN5/f7CUUJOU1dXKdiordmNYMAMBZEViCpMx58nZQ16gwdmgGAKAVfFIGiWcNFnpXAABoFYElSJghBABA2xFYgqTsVA8LgQUAgNYRWILEM6WZReMAAGgVgSVIPKvcsgYLAACtIrAECT0sAAC0HYElSBjDAgBA2xFYgsS9Dgs7NQMA0DoCS5CUVrl3aqaHBQCA1hBYguB4XaOcdY2SGMMCAEBbEFiCwD1DyGGzKibc6w2zAQA45xBYgqDstBlCFoslyK0BACD0EViCwN3DwgwhAADahsASBKzBAgCAdwgsQdC0UzM9LAAAtAWBJQiadmqmhwUAgLYgsASBe5VbbgkBANA2BJYgcK9yyy0hAADahsASBO5BtwkxBBYAANqCwBIEnltC0dwSAgCgLQgsAeZyGadtfEgPCwAAbUFgCbCK4/VqdBmSpO70sAAA0CYElgBzr3IbG2GXw86vHwCAtuATM8A8A265HQQAQJsRWAKsjMACAIDXCCwB5r4lxKJxAAC0HYElwEqrCCwAAHiLwBJgpaxyCwCA1wgsAeZeNI6NDwEAaDsCS4C5B93GM+gWAIA2I7AEGKvcAgDgPQJLgJVWM+gWAABvEVgC6ER9o6pONEiSEhh0CwBAmxFYAujoqdtBdqtFsZH2ILcGAICOg8ASQE0Dbh2yWCxBbg0AAB0HgSWASp3uKc3cDgIAwBsElgBiSjMAAO1DYAkgz6Jx0cwQAgDAGwSWAGJKMwAA7UNgCSBuCQEA0D4ElgBq2viQHhYAALxBYAkgzxiWGHpYAADwBoElgNy3hFjlFgAA7xBYAsQwDJU5GXQLAEB7EFgCpPJ4g+obDUlSd8awAADgFQJLgLhXuY0JtysizBbk1gAA0LEQWALk9H2EAACAdwgsAeKZIcQaLAAAeI3AEiCeNVjoYQEAwGsElgAprXLPEKKHBQAAbxFYAsQ9pZmNDwEA8B6BJUDYRwgAgPZrV2BZvny5+vbtq4iICGVkZGjLli3fe219fb1++9vfqn///oqIiFB6erry8vJ8qtkRMUsIAID28zqwrF69Wrm5uVq0aJG2bt2q9PR0ZWVl6fDhwy1eP3/+fD311FN6/PHH9dVXX2nGjBm69tpr9fnnn7e7ZkfkXoeFWUIAAHjPYhiG4c0DMjIydPHFF+uJJ56QJLlcLqWmpurOO+/Uvffee8b1KSkpuv/++zVz5kzPueuuu06RkZF66aWX2lXzuyorKxUXF6eKigrFxsZ683ICJv3B91RxvF7v5/5YA3rEBLs5AAAEnTef3171sNTV1amgoECZmZlNBaxWZWZmauPGjS0+pra2VhEREc3ORUZG6uOPP/apZmVlZbMjlNU1uFRxvF6SFM/GhwAAeM2rwFJaWqrGxkYlJSU1O5+UlKTi4uIWH5OVlaWlS5dq165dcrlcWrdundasWaOioqJ211y8eLHi4uI8R2pqqjcvI+COnlqDxWa1KC4yLMitAQCg4/H7LKHHHntM559/vgYNGiSHw6FZs2YpJydHVmv7n3revHmqqKjwHPv37zexxeYrPbXKbfdoh6xWS5BbAwBAx+NVakhISJDNZlNJSUmz8yUlJUpOTm7xMYmJiXrjjTfkdDq1b98+ff311+rSpYv69evX7prh4eGKjY1tdoSyMvcqt6zBAgBAu3gVWBwOh0aMGKH8/HzPOZfLpfz8fI0aNeqsj42IiFCvXr3U0NCgv//975owYYLPNTsK9z5CiTGMXwEAoD3s3j4gNzdX06ZN08iRI3XJJZdo2bJlcjqdysnJkSTdfPPN6tWrlxYvXixJ2rx5sw4ePKjhw4fr4MGDeuCBB+RyuXT33Xe3uWZH51mDhR4WAADaxevAMnHiRB05ckQLFy5UcXGxhg8frry8PM+g2cLCwmbjU06cOKH58+drz5496tKli6688kq9+OKL6tq1a5trdnTuMSyscgsAQPt4vQ5LKAr1dVh+/eq/9fetB3T3uIH6r58OCHZzAAAICX5bhwXt07TxIT0sAAC0B4ElANxjWBJiGMMCAEB7EFgCwD1LiFVuAQBoHwKLnxmGoVInOzUDAOALAoufVdU2qK7BJYkeFgAA2ovA4mfu8SvRDpsiHbYgtwYAgI6JwOJnZazBAgCAzwgsflbqniHE+BUAANqNwOJn7jVY6GEBAKD9CCx+VkYPCwAAPiOw+Fkpa7AAAOAzAoufeXZqpocFAIB2I7D4GTs1AwDgOwKLn5U5GcMCAICvCCx+5l6HJYEeFgAA2o3A4kcNjS4dq6mXJMVH08MCAEB7EVj86Oip20FWi9Q1isACAEB7EVj8yL3Kbfdoh2xWS5BbAwBAx0Vg8SPPKreswQIAgE8ILH7kWeU2httBAAD4gsDiR6xyCwCAOQgsfuReg4VVbgEA8A2BxY9Kq1iDBQAAMxBY/MjTw8IaLAAA+ITA4kdl7CMEAIApCCx+5F6HhX2EAADwDYHFTwzD8KzDwhgWAAB8Q2DxE2ddo07UuyQxSwgAAF8RWPzEPX4lMsymKIc9yK0BAKBjI7D4iXv8Cr0rAAD4jsDiJ+4eFsavAADgOwKLn7jXYGGGEAAAviOw+EkZ+wgBAGAaAoufMIYFAADzEFj8pJRVbgEAMA2BxU/KWOUWAADTEFj8hFVuAQAwD4HFT8oYwwIAgGkILH7Q6DJ0tOZUYGGWEAAAPiOw+MFRZ50MQ7JYpG5RYcFuDgAAHR6BxQ/c41e6RTlkt/ErBgDAV3ya+oFn/Eo041cAADADgcUPStlHCAAAUxFY/IAZQgAAmIvA4geswQIAgLkILH5QWsUYFgAAzERg8QN3Dwv7CAEAYA4Cix+wUzMAAOYisPgBY1gAADAXgcUP2KkZAABzEVhMVlPXoJq6RkmMYQEAwCwEFpO5e1fC7VZFO2xBbg0AAJ0DgcVkp69ya7FYgtwaAAA6h3YFluXLl6tv376KiIhQRkaGtmzZctbrly1bpoEDByoyMlKpqamaM2eOTpw44fn5Aw88IIvF0uwYNGhQe5oWdIxfAQDAfHZvH7B69Wrl5uZqxYoVysjI0LJly5SVlaWdO3eqR48eZ1z/8ssv695779WqVas0evRoffPNN5o+fbosFouWLl3quW7IkCF6//33mxpm97ppIYE1WAAAMJ/XPSxLly7V7bffrpycHA0ePFgrVqxQVFSUVq1a1eL1n3zyiS677DLdeOON6tu3r8aOHavJkyef0Stjt9uVnJzsORISEtr3ioKslJ2aAQAwnVeBpa6uTgUFBcrMzGwqYLUqMzNTGzdubPExo0ePVkFBgSeg7NmzR++8846uvPLKZtft2rVLKSkp6tevn6ZMmaLCwsLvbUdtba0qKyubHaGiaeNDelgAADCLV/ddSktL1djYqKSkpGbnk5KS9PXXX7f4mBtvvFGlpaUaM2aMDMNQQ0ODZsyYofvuu89zTUZGhp577jkNHDhQRUVFevDBB/WjH/1I27dvV0xMzBk1Fy9erAcffNCbpgdM06BbelgAADCL32cJrV+/Xo888oj+/Oc/a+vWrVqzZo3Wrl2rhx56yHPN+PHjdf3112vYsGHKysrSO++8o/Lycr366qst1pw3b54qKio8x/79+/39MtqsaQwLgQUAALN41cOSkJAgm82mkpKSZudLSkqUnJzc4mMWLFigqVOn6rbbbpMkDR06VE6nU7/85S91//33y2o9MzN17dpVF1xwgXbv3t1izfDwcIWHh+Ytl6ZZQqHZPgAAOiKvelgcDodGjBih/Px8zzmXy6X8/HyNGjWqxcfU1NScEUpstpMLqhmG0eJjqqur9e2336pnz57eNC8kNA26JbAAAGAWr+cO5+bmatq0aRo5cqQuueQSLVu2TE6nUzk5OZKkm2++Wb169dLixYslSdnZ2Vq6dKkuvPBCZWRkaPfu3VqwYIGys7M9weU3v/mNsrOzlZaWpkOHDmnRokWy2WyaPHmyiS/V/1wuQ0edjGEBAMBsXgeWiRMn6siRI1q4cKGKi4s1fPhw5eXleQbiFhYWNutRmT9/viwWi+bPn6+DBw8qMTFR2dnZevjhhz3XHDhwQJMnT1ZZWZkSExM1ZswYbdq0SYmJiSa8xMApP14v16lOo25MawYAwDQW4/vuy3QglZWViouLU0VFhWJjY4PWjm9KqjT2jx+qa1SYti0cG7R2AADQEXjz+c1eQiZyT2lm0TgAAMxFYDERM4QAAPAPAouJyk7bqRkAAJiHwGKiMqd7WX5uCQEAYCYCi4maxrDQwwIAgJkILCbyLBpHDwsAAKYisJiojI0PAQDwCwKLidxjWBh0CwCAuQgsJirz3BIisAAAYCYCi0lO1DequrZBEmNYAAAwG4HFJO4ZQg6bVTHhXm/RBAAAzoLAYpKy02YIWSyWILcGAIDOhcBikjLnqTVYuB0EAIDpCCwmKWUfIQAA/IbAYhLPLSFWuQUAwHQEFpOwaBwAAP5DYDGJZx8hAgsAAKYjsJjEs1Mzt4QAADAdgcUknkG3MQQWAADMRmAxiXsMS3w0t4QAADAbgcUELpeho2x8CACA3xBYTFB5ol4NLkOS1J0eFgAATEdgMYF7hlBshF0OO79SAADMxqerCVjlFgAA/yKwmKCMwAIAgF8RWEzAxocAAPgXgcUE7ltCBBYAAPyDwGKCpjVYuCUEAIA/EFhMUMrGhwAA+BWBxQRlnltC9LAAAOAPBBYTlLHKLQAAfkVgMYH7lhCDbgEA8A8Ci49qGxpVdaJBkpTAoFsAAPyCwOIj96aHdqtFsZH2ILcGAIDOicDio9KqpjVYLBZLkFsDAEDnRGDxUamTNVgAAPA3AouPPPsIxRBYAADwFwKLj9yr3CZEM0MIAAB/IbD4yL0GC1OaAQDwHwKLj5rWYOGWEAAA/kJg8ZFnp2ZuCQEA4DcEFh95xrDQwwIAgN8QWHzkmSVEYAEAwG8ILD4wDENlTvYRAgDA3wgsPqg80aD6RkOS1J0xLAAA+A2BxQfuGUIx4XZFhNmC3BoAADovAosP3ONXuB0EAIB/EVh8wAwhAAACg8Dig1JWuQUAICAILD4oY5VbAAACgsDiA88aLMwQAgDArwgsPmAfIQAAAoPA4gNmCQEAEBjtCizLly9X3759FRERoYyMDG3ZsuWs1y9btkwDBw5UZGSkUlNTNWfOHJ04ccKnmqGg1MksIQAAAsHrwLJ69Wrl5uZq0aJF2rp1q9LT05WVlaXDhw+3eP3LL7+se++9V4sWLdKOHTu0cuVKrV69Wvfdd1+7a4aKpn2E6GEBAMCfvA4sS5cu1e23366cnBwNHjxYK1asUFRUlFatWtXi9Z988okuu+wy3Xjjjerbt6/Gjh2ryZMnN+tB8bZmKKhrcKnieL0kKT6aHhYAAPzJq8BSV1engoICZWZmNhWwWpWZmamNGze2+JjRo0eroKDAE1D27Nmjd955R1deeWW7a9bW1qqysrLZEWjHak72rtisFsVFhgX8+QEAOJfYvbm4tLRUjY2NSkpKanY+KSlJX3/9dYuPufHGG1VaWqoxY8bIMAw1NDRoxowZnltC7am5ePFiPfjgg9403XRHqk6OX+ke7ZDVaglqWwAA6Oz8Pkto/fr1euSRR/TnP/9ZW7du1Zo1a7R27Vo99NBD7a45b948VVRUeI79+/eb2OK2KXOvcssaLAAA+J1XPSwJCQmy2WwqKSlpdr6kpETJycktPmbBggWaOnWqbrvtNknS0KFD5XQ69ctf/lL3339/u2qGh4crPDy440bcq9wmxjB+BQAAf/Oqh8XhcGjEiBHKz8/3nHO5XMrPz9eoUaNafExNTY2s1uZPY7PZJEmGYbSrZijwrMFCDwsAAH7nVQ+LJOXm5mratGkaOXKkLrnkEi1btkxOp1M5OTmSpJtvvlm9evXS4sWLJUnZ2dlaunSpLrzwQmVkZGj37t1asGCBsrOzPcGltZqhyL0GC6vcAgDgf14HlokTJ+rIkSNauHChiouLNXz4cOXl5XkGzRYWFjbrUZk/f74sFovmz5+vgwcPKjExUdnZ2Xr44YfbXDMUscotAACBYzEMwwh2I3xVWVmpuLg4VVRUKDY2NiDPOf3ZLVq/84h+f90w3XBxakCeEwCAzsSbz2/2EmonelgAAAgcAks7uWcJsY8QAAD+R2BpB8MwVOqkhwUAgEAhsLRDdW2D6hpckthHCACAQCCwtIN7/Eq0w6ZIhy3IrQEAoPMjsLRDaTVrsAAAEEgElnYoZYYQAAABRWBphzInM4QAAAgkAks7uMewJNDDAgBAQBBY2sG9BgszhAAACAwCSzuwBgsAAIFFYGmH0ipmCQEAEEgElnYoczKGBQCAQCKwtAP7CAEAEFgEFi81NLp0rKZekhQfTQ8LAACBQGDx0tGak7eDrBapaxSBBQCAQCCweMm9Bkv3aIdsVkuQWwMAwLmBwOKlUtZgAQAg4AgsXvKschvD7SAAAAKFwOIlelgAAAg8AouXyljlFgCAgCOweIk1WAAACDwCi5dKT41hYQ0WAAACh8DiJc9OzfSwAAAQMAQWL7l7WNhHCACAwCGweMEwDJU5GcMCAECgEVi8UFPXqBP1LknMEgIAIJAILF5wLxoXGWZTlMMe5NYAAHDuILB44YhnwC29KwAABBKBxQvMEAIAIDgILF5wr3KbSA8LAAABRWDxQhn7CAEAEBQEFi94VrmlhwUAgIAisHihaeNDelgAAAgkAosXSqvci8bRwwIAQCARWLzAKrcAAAQHgcULZYxhAQAgKAgsbdToMnS05lRgYZYQAAABRWBpo2M1dTIMyWKRukWFBbs5AACcUwgsbeS+HdQtyiG7jV8bAACBxCdvG5V6Fo1j/AoAAIFGYGkjd2BhhhAAAIFHYGkjZggBABA8BJY2Yg0WAACCh8DSRp4eFsawAAAQcASWNmra+JAeFgAAAo3A0kaeWUKMYQEAIOAILG3EGBYAAIKHwNJG7jEs7NQMAEDgEVjaoKauQTV1jZIYwwIAQDAQWNrA3bsSbrcq2mELcmsAADj3EFjaoMzpvh0ULovFEuTWAABw7iGwtEFpFTOEAAAIpnYFluXLl6tv376KiIhQRkaGtmzZ8r3X/vSnP5XFYjnjuOqqqzzXTJ8+/Yyfjxs3rj1N8wtmCAEAEFx2bx+wevVq5ebmasWKFcrIyNCyZcuUlZWlnTt3qkePHmdcv2bNGtXV1Xm+LysrU3p6uq6//vpm140bN07PPvus5/vw8NAJB6WscgsAQFB53cOydOlS3X777crJydHgwYO1YsUKRUVFadWqVS1e3717dyUnJ3uOdevWKSoq6ozAEh4e3uy6bt26te8V+UEZq9wCABBUXgWWuro6FRQUKDMzs6mA1arMzExt3LixTTVWrlypSZMmKTo6utn59evXq0ePHho4cKDuuOMOlZWVfW+N2tpaVVZWNjv8qemWED0sAAAEg1eBpbS0VI2NjUpKSmp2PikpScXFxa0+fsuWLdq+fbtuu+22ZufHjRunF154Qfn5+VqyZIk2bNig8ePHq7GxscU6ixcvVlxcnOdITU315mV4ramHhcACAEAweD2GxRcrV67U0KFDdckllzQ7P2nSJM/XQ4cO1bBhw9S/f3+tX79eV1xxxRl15s2bp9zcXM/3lZWVfg0tnn2EorklBABAMHjVw5KQkCCbzaaSkpJm50tKSpScnHzWxzqdTr3yyiu69dZbW32efv36KSEhQbt3727x5+Hh4YqNjW12+FNpddM6LAAAIPC8CiwOh0MjRoxQfn6+55zL5VJ+fr5GjRp11se+9tprqq2t1U033dTq8xw4cEBlZWXq2bOnN83zC5fL0FHGsAAAEFRezxLKzc3VM888o+eff147duzQHXfcIafTqZycHEnSzTffrHnz5p3xuJUrV+qaa65RfHx8s/PV1dWaO3euNm3apP/85z/Kz8/XhAkTNGDAAGVlZbXzZZmn/Hi9XMbJr7sxrRkAgKDwegzLxIkTdeTIES1cuFDFxcUaPny48vLyPANxCwsLZbU2z0E7d+7Uxx9/rPfee++MejabTV988YWef/55lZeXKyUlRWPHjtVDDz0UEmuxlJ0av9I1KkxhNhYGBgAgGCyGYRjBboSvKisrFRcXp4qKCtPHs3zybalufGaz+idGK//XPzW1NgAA5zJvPr/pMmhFGQNuAQAIOgJLK9y3hAgsAAAED4GlFWVOFo0DACDYCCytaNr4kB4WAACChcDSCvctIXpYAAAIHgJLK0qrWTQOAIBgI7C0wj2GhUG3AAAED4GlFU07NRNYAAAIFgLLWZyob1R1bYMkxrAAABBMXi/Nfy5xGYbmZg1UWXWdYsL5VQEAECx8Cp9FlMOumZcPCHYzAAA453FLCAAAhDwCCwAACHkEFgAAEPIILAAAIOQRWAAAQMgjsAAAgJBHYAEAACGPwAIAAEIegQUAAIQ8AgsAAAh5BBYAABDyCCwAACDkEVgAAEDI6xS7NRuGIUmqrKwMcksAAEBbuT+33Z/jZ9MpAktVVZUkKTU1NcgtAQAA3qqqqlJcXNxZr7EYbYk1Ic7lcunQoUOKiYmRxWIxtXZlZaVSU1O1f/9+xcbGmlrb3/U7cts7ev2O3PaOXr8jt72j1+/Ibfd3/Y7cdn/WNwxDVVVVSklJkdV69lEqnaKHxWq1qnfv3n59jtjYWL/8JQhE/Y7c9o5evyO3vaPX78ht7+j1O3Lb/V2/I7fdX/Vb61lxY9AtAAAIeQQWAAAQ8ggsrQgPD9eiRYsUHh7e4ep35LZ39Podue0dvX5HbntHr9+R2+7v+h257YGo3xadYtAtAADo3OhhAQAAIY/AAgAAQh6BBQAAhDwCCwAACHkElu/x4YcfKjs7WykpKbJYLHrjjTdMq7148WJdfPHFiomJUY8ePXTNNddo586dptV/8sknNWzYMM8CP6NGjdI///lP0+p/1+9+9ztZLBbNnj3blHoPPPCALBZLs2PQoEGm1JakgwcP6qabblJ8fLwiIyM1dOhQffbZZ6bU7tu37xltt1gsmjlzpin1GxsbtWDBAp133nmKjIxU//799dBDD7VpH462qKqq0uzZs5WWlqbIyEiNHj1an376abtqtfYeMgxDCxcuVM+ePRUZGanMzEzt2rXLtPpr1qzR2LFjFR8fL4vFom3btpnW/vr6et1zzz0aOnSooqOjlZKSoptvvlmHDh0yrf0PPPCABg0apOjoaHXr1k2ZmZnavHmzKbVPN2PGDFksFi1btsy0tk+fPv2M98C4ceNMqy9JO3bs0NVXX624uDhFR0fr4osvVmFhoc+1W3r/WiwW/eEPfzCl7dXV1Zo1a5Z69+6tyMhIDR48WCtWrGhT7bbULykp0fTp05WSkqKoqCiNGzeuze+rtnw2nThxQjNnzlR8fLy6dOmi6667TiUlJW1uvy8ILN/D6XQqPT1dy5cvN732hg0bNHPmTG3atEnr1q1TfX29xo4dK6fTaUr93r1763e/+50KCgr02Wef6Wc/+5kmTJig//u//zOl/uk+/fRTPfXUUxo2bJipdYcMGaKioiLP8fHHH5tS99ixY7rssssUFhamf/7zn/rqq6/06KOPqlu3bqbU//TTT5u1e926dZKk66+/3pT6S5Ys0ZNPPqknnnhCO3bs0JIlS/T73/9ejz/+uCn1b7vtNq1bt04vvviivvzyS40dO1aZmZk6ePCg17Vaew/9/ve/15/+9CetWLFCmzdvVnR0tLKysnTixAlT6judTo0ZM0ZLlizxuu2t1a+pqdHWrVu1YMECbd26VWvWrNHOnTt19dVXm1Jfki644AI98cQT+vLLL/Xxxx+rb9++Gjt2rI4cOeJzbbfXX39dmzZtUkpKSpvb3db648aNa/Ze+Nvf/mZa/W+//VZjxozRoEGDtH79en3xxRdasGCBIiIifK59epuLioq0atUqWSwWXXfddaa0PTc3V3l5eXrppZe0Y8cOzZ49W7NmzdKbb77pc33DMHTNNddoz549+sc//qHPP/9caWlpyszMbNPnS1s+m+bMmaO33npLr732mjZs2KBDhw7p5z//eZva7jMDrZJkvP76636rf/jwYUOSsWHDBr89R7du3Yy//OUvptasqqoyzj//fGPdunXGT37yE+Ouu+4ype6iRYuM9PR0U2p91z333GOMGTPGL7Vbctdddxn9+/c3XC6XKfWuuuoq45Zbbml27uc//7kxZcoUn2vX1NQYNpvNePvtt5udv+iii4z777/fp9rffQ+5XC4jOTnZ+MMf/uA5V15eboSHhxt/+9vffK5/ur179xqSjM8//9zrum2p77ZlyxZDkrFv3z6/1K+oqDAkGe+//74ptQ8cOGD06tXL2L59u5GWlmb88Y9/9Kru2epPmzbNmDBhQrvqtaX+xIkTjZtuuskvtb9rwoQJxs9+9jPT6g8ZMsT47W9/2+xce99j362/c+dOQ5Kxfft2z7nGxkYjMTHReOaZZ7yu/93PpvLyciMsLMx47bXXPNfs2LHDkGRs3LjR6/reooclBFRUVEiSunfvbnrtxsZGvfLKK3I6nRo1apSptWfOnKmrrrpKmZmZptaVpF27diklJUX9+vXTlClT2tTV2xZvvvmmRo4cqeuvv149evTQhRdeqGeeecaU2t9VV1enl156Sbfccotpm3KOHj1a+fn5+uabbyRJ//73v/Xxxx9r/PjxPtduaGhQY2PjGf9KjYyMNK2Hy23v3r0qLi5u9ncnLi5OGRkZ2rhxo6nPFSgVFRWyWCzq2rWr6bXr6ur09NNPKy4uTunp6T7Xc7lcmjp1qubOnashQ4aY0MIzrV+/Xj169NDAgQN1xx13qKyszJS6LpdLa9eu1QUXXKCsrCz16NFDGRkZpt62dyspKdHatWt16623mlZz9OjRevPNN3Xw4EEZhqEPPvhA33zzjcaOHetz7draWklq9h62Wq0KDw9v13v4u59NBQUFqq+vb/a+HTRokPr06ROQ9y2BJchcLpdmz56tyy67TD/84Q9Nq/vll1+qS5cuCg8P14wZM/T6669r8ODBptV/5ZVXtHXrVi1evNi0mm4ZGRl67rnnlJeXpyeffFJ79+7Vj370I1VVVflce8+ePXryySd1/vnn691339Udd9yhX/3qV3r++edNaHlzb7zxhsrLyzV9+nTTat57772aNGmSBg0apLCwMF144YWaPXu2pkyZ4nPtmJgYjRo1Sg899JAOHTqkxsZGvfTSS9q4caOKiopMaH2T4uJiSVJSUlKz80lJSZ6fdSQnTpzQPffco8mTJ5u6Mdzbb7+tLl26KCIiQn/84x+1bt06JSQk+Fx3yZIlstvt+tWvfmVCK880btw4vfDCC8rPz9eSJUu0YcMGjR8/Xo2NjT7XPnz4sKqrq/W73/1O48aN03vvvadrr71WP//5z7VhwwYTWt/k+eefV0xMjKm3PB5//HENHjxYvXv3lsPh0Lhx47R8+XL9+Mc/9rm2OzzMmzdPx44dU11dnZYsWaIDBw54/R5u6bOpuLhYDofjjFAeqPdtp9ituSObOXOmtm/fbvq/YAcOHKht27apoqJC//u//6tp06Zpw4YNpoSW/fv366677tK6devadM/YW6f3FgwbNkwZGRlKS0vTq6++6vO/dFwul0aOHKlHHnlEknThhRdq+/btWrFihaZNm+ZT7e9auXKlxo8f7/X4gLN59dVX9de//lUvv/yyhgwZom3btmn27NlKSUkxpf0vvviibrnlFvXq1Us2m00XXXSRJk+erIKCAhNa3znV19frhhtukGEYevLJJ02tffnll2vbtm0qLS3VM888oxtuuEGbN29Wjx492l2zoKBAjz32mLZu3Wpaz993TZo0yfP10KFDNWzYMPXv31/r16/XFVdc4VNtl8slSZowYYLmzJkjSRo+fLg++eQTrVixQj/5yU98qn+6VatWacqUKab+f+7xxx/Xpk2b9OabbyotLU0ffvihZs6cqZSUFJ97q8PCwrRmzRrdeuut6t69u2w2mzIzMzV+/HivB+b767PJF/SwBNGsWbP09ttv64MPPlDv3r1Nre1wODRgwACNGDFCixcvVnp6uh577DFTahcUFOjw4cO66KKLZLfbZbfbtWHDBv3pT3+S3W435V9Rp+vatasuuOAC7d692+daPXv2PCO0/eAHPzDtlpPbvn379P777+u2224zte7cuXM9vSxDhw7V1KlTNWfOHNN6uvr3768NGzaourpa+/fv15YtW1RfX69+/fqZUt8tOTlZks6YXVBSUuL5WUfgDiv79u3TunXrTO1dkaTo6GgNGDBAl156qVauXCm73a6VK1f6VPOjjz7S4cOH1adPH8/7d9++ffr1r3+tvn37mtPw7+jXr58SEhJMeQ8nJCTIbrf7/X380UcfaefOnaa+h48fP6777rtPS5cuVXZ2toYNG6ZZs2Zp4sSJ+p//+R9TnmPEiBHatm2bysvLVVRUpLy8PJWVlXn1Hv6+z6bk5GTV1dWpvLy82fWBet8SWILAMAzNmjVLr7/+uv71r3/pvPPO8/tzulwuz/1NX11xxRX68ssvtW3bNs8xcuRITZkyRdu2bZPNZjPledyqq6v17bffqmfPnj7Xuuyyy86YpvfNN98oLS3N59qne/bZZ9WjRw9dddVVptatqamR1dr8bWuz2Tz/6jRLdHS0evbsqWPHjundd9/VhAkTTK1/3nnnKTk5Wfn5+Z5zlZWV2rx5s+ljrfzFHVZ27dql999/X/Hx8X5/TjPex1OnTtUXX3zR7P2bkpKiuXPn6t133zWppc0dOHBAZWVlpryHHQ6HLr74Yr+/j1euXKkRI0aYMmbIrb6+XvX19QF5D8fFxSkxMVG7du3SZ5991qb3cGufTSNGjFBYWFiz9+3OnTtVWFgYkPctt4S+R3V1dbN/Dezdu1fbtm1T9+7d1adPH59qz5w5Uy+//LL+8Y9/KCYmxnPvLy4uTpGRkT7VlqR58+Zp/Pjx6tOnj6qqqvTyyy9r/fr1pv3PKCYm5ozxNtHR0YqPjzdlHM5vfvMbZWdnKy0tTYcOHdKiRYtks9k0efJkn2vPmTNHo0eP1iOPPKIbbrhBW7Zs0dNPP62nn37a59puLpdLzz77rKZNmya73dy3WHZ2th5++GH16dNHQ4YM0eeff66lS5fqlltuMaX+u+++K8MwNHDgQO3evVtz587VoEGDlJOT43Wt1t5Ds2fP1n//93/r/PPP13nnnacFCxYoJSVF11xzjSn1jx49qsLCQs/aKO4PuOTk5Db9a/Bs9Xv27Klf/OIX2rp1q95++201NjZ63sfdu3eXw+HwqX58fLwefvhhXX311erZs6dKS0u1fPlyHTx4sE1T5Fv73Xw3XIWFhSk5OVkDBw5stXZr9bt3764HH3xQ1113nZKTk/Xtt9/q7rvv1oABA5SVleVz/T59+mju3LmaOHGifvzjH+vyyy9XXl6e3nrrLa1fv97n2tLJ8Pzaa6/p0UcfbVN7van/k5/8RHPnzlVkZKTS0tK0YcMGvfDCC1q6dKkp9V977TUlJiaqT58++vLLL3XXXXfpmmuuadOg3tY+m+Li4nTrrbcqNzdX3bt3V2xsrO68806NGjVKl156qZe/qXbw+zykDuqDDz4wJJ1xTJs2zefaLdWVZDz77LM+1zYMw7jllluMtLQ0w+FwGImJicYVV1xhvPfee6bU/j5mTmueOHGi0bNnT8PhcBi9evUyJk6caOzevduU2oZhGG+99Zbxwx/+0AgPDzcGDRpkPP3006bVNgzDePfddw1Jxs6dO02taxiGUVlZadx1111Gnz59jIiICKNfv37G/fffb9TW1ppSf/Xq1Ua/fv0Mh8NhJCcnGzNnzjTKy8vbVau195DL5TIWLFhgJCUlGeHh4cYVV1zh1e+stfrPPvtsiz9ftGiRz/XdU6VbOj744AOf6x8/fty49tprjZSUFMPhcBg9e/Y0rr76amPLli2m/G6+y9tpzWerX1NTY4wdO9ZITEw0wsLCjLS0NOP22283iouLTanvtnLlSmPAgAFGRESEkZ6ebrzxxhum1X7qqaeMyMjIdv3db61+UVGRMX36dCMlJcWIiIgwBg4caDz66KNtXvqgtfqPPfaY0bt3byMsLMzo06ePMX/+/Db//6Etn03Hjx83/uu//svo1q2bERUVZVx77bVGUVGRN7+idrOcaiQAAEDIYgwLAAAIeQQWAAAQ8ggsAAAg5BFYAABAyCOwAACAkEdgAQAAIY/AAgAAQh6BBQAAhDwCCwAACHkEFgAAEPIILAAAIOQRWAAAQMj7/wG6b57iV4XKZwAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"code","source":["config = Config()\n","config.n = 8\n","config.agg_strategy = 'last'\n","\n","num_trials = 30\n","trial_max_score_arr = np.zeros(config.n)\n","for trial_id in range(num_trials):\n","    trial_max_score_arr += _maxk_sequence(input_batch['problem'], config, llm=llm, prm=prm)\n","\n","trial_max_score_arr /= num_trials"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nn_9rQj1SSgy","executionInfo":{"status":"ok","timestamp":1740607511827,"user_tz":420,"elapsed":92895,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"46abb079-bf19-40ef-f659-00bc82331b0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1.0, 1.0, 1.0, 1.0, 1.0, 0.376953125, 1.0, 0.98828125]]\n","[[0.99609375, 0.1484375, 1.0, 1.0, 0.9921875, 1.0, 0.053466796875, 1.0]]\n","[[0.09521484375, 1.0, 0.07568359375, 0.99609375, 0.99609375, 0.1484375, 0.81640625, 0.96875]]\n","[[0.99609375, 0.99609375, 1.0, 1.0, 0.62109375, 1.0, 1.0, 1.0]]\n","[[0.053466796875, 0.99609375, 0.99609375, 0.10693359375, 0.09521484375, 1.0, 0.053466796875, 1.0]]\n","[[0.98828125, 0.99609375, 1.0, 1.0, 0.984375, 0.408203125, 1.0, 0.3203125]]\n","[[0.62109375, 0.0849609375, 0.04736328125, 1.0, 0.033203125, 0.99609375, 1.0, 1.0]]\n","[[0.02294921875, 0.99609375, 0.9921875, 1.0, 0.98828125, 0.99609375, 1.0, 0.99609375]]\n","[[0.984375, 1.0, 1.0, 0.2451171875, 1.0, 1.0, 0.5, 0.90625]]\n","[[0.98828125, 0.99609375, 0.9921875, 0.53125, 0.376953125, 1.0, 1.0, 0.07568359375]]\n","[[1.0, 1.0, 0.99609375, 0.984375, 0.07568359375, 0.9921875, 1.0, 1.0]]\n","[[0.99609375, 0.99609375, 0.97265625, 1.0, 1.0, 1.0, 0.98828125, 0.99609375]]\n","[[0.99609375, 0.0849609375, 0.9609375, 0.99609375, 0.26953125, 0.81640625, 1.0, 0.22265625]]\n","[[0.99609375, 0.1640625, 0.98046875, 1.0, 0.99609375, 0.984375, 1.0, 0.9609375]]\n","[[0.99609375, 1.0, 0.0673828125, 0.96875, 1.0, 1.0, 1.0, 0.99609375]]\n","[[0.07568359375, 1.0, 0.99609375, 0.99609375, 0.1826171875, 0.59375, 0.294921875, 0.96875]]\n","[[1.0, 0.5625, 0.99609375, 0.99609375, 1.0, 1.0, 0.984375, 0.9921875]]\n","[[0.9765625, 0.4375, 0.99609375, 1.0, 1.0, 0.1484375, 1.0, 0.2021484375]]\n","[[1.0, 1.0, 0.98046875, 0.99609375, 0.99609375, 0.9921875, 0.9921875, 0.9921875]]\n","[[1.0, 0.8359375, 1.0, 0.99609375, 0.99609375, 1.0, 1.0, 0.99609375]]\n","[[0.87890625, 1.0, 0.99609375, 0.96875, 0.87890625, 0.9921875, 0.3203125, 0.9921875]]\n","[[0.77734375, 0.73046875, 0.99609375, 1.0, 0.99609375, 1.0, 1.0, 0.99609375]]\n","[[0.953125, 0.9921875, 1.0, 1.0, 1.0, 0.81640625, 0.99609375, 1.0]]\n","[[1.0, 1.0, 0.99609375, 0.98828125, 0.93359375, 0.99609375, 0.9921875, 0.99609375]]\n","[[0.8359375, 1.0, 0.99609375, 0.95703125, 1.0, 0.0849609375, 0.2451171875, 0.9921875]]\n","[[1.0, 0.9921875, 1.0, 0.98046875, 0.96875, 0.99609375, 1.0, 0.06005859375]]\n","[[0.796875, 1.0, 0.98046875, 0.6796875, 0.98046875, 0.99609375, 0.04736328125, 1.0]]\n","[[0.99609375, 1.0, 0.95703125, 0.9609375, 0.65234375, 0.87890625, 1.0, 1.0]]\n","[[0.73046875, 0.77734375, 0.9921875, 1.0, 1.0, 1.0, 1.0, 1.0]]\n","[[0.349609375, 0.8515625, 0.99609375, 0.99609375, 0.1640625, 1.0, 0.99609375, 0.2451171875]]\n"]}]},{"cell_type":"code","source":["xrange = np.arange(1,config.n+1)\n","plt.plot(xrange, trial_max_score_arr)\n","plt.xticks(xrange)\n","plt.show()"],"metadata":{"id":"d_XJc1yIErfb","colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"status":"ok","timestamp":1740607524972,"user_tz":420,"elapsed":111,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"f20e3426-30bb-45f4-e3cf-bad80eb09e7a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["question_text = \"Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\theta),$ where $r > 0$ and $0 \\le \\theta < 2 \\pi.$\"\n","input_batch = {\"problem\": [question_text]}"],"metadata":{"id":"3Smzrd1TEgnf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["first_step = \" ## Step 1: Convert the given rectangular coordinates $(0,3)$ to polar coordinates.\\nTo convert from rectangular coordinates to polar coordinates, we use the formulas $r = \\\\sqrt{x^2 + y^2}$ and $\\\\theta = \\\\arctan{\\\\left(\\\\frac{y}{x}\\\\right)}$. Here, $x=0$ and $y=3$.\\n\\n\"\n","batch_of_prompts = [first_step + question_text]\n","\n","config = Config()\n","config.n = 8\n","config.agg_strategy = 'last'\n","\n","num_trials = 30\n","trial_max_score_arr = np.zeros(config.n)\n","for trial_id in range(num_trials):\n","    trial_max_score_arr += _maxk_sequence(batch_of_prompts, config, llm=llm, prm=prm)\n","\n","trial_max_score_arr /= num_trials"],"metadata":{"id":"9a40-I5-TZ7V","colab":{"base_uri":"https://localhost:8080/","height":755},"executionInfo":{"status":"error","timestamp":1740608650594,"user_tz":420,"elapsed":62449,"user":{"displayName":"Tuan Nguyen","userId":"16115406941211139628"}},"outputId":"ac01ad5e-e77a-46dc-c006-88abaa5e336a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.99609375, 0.95703125, 0.9140625, 0.70703125, 0.9921875, 0.796875, 0.99609375, 0.9921875]]\n","[[0.9921875, 0.99609375, 0.9453125, 0.99609375, 0.9921875, 0.984375, 0.99609375, 0.04736328125]]\n","[[0.9921875, 0.9765625, 0.94140625, 0.65234375, 1.0, 0.98828125, 0.9609375, 0.99609375]]\n","[[0.62109375, 0.9921875, 0.9921875, 0.98046875, 0.99609375, 0.953125, 0.9765625, 0.98046875]]\n","[[0.10693359375, 0.9921875, 0.8671875, 0.98828125, 0.99609375, 0.98828125, 0.99609375, 0.9921875]]\n","[[0.9921875, 1.0, 0.98828125, 0.9921875, 0.9921875, 0.9921875, 0.2021484375, 0.9921875]]\n","[[0.98046875, 0.96875, 0.81640625, 0.984375, 0.9921875, 0.9921875, 0.99609375, 0.99609375]]\n","[[1.0, 0.0849609375, 0.99609375, 0.98046875, 0.73046875, 0.99609375, 0.99609375, 0.99609375]]\n","[[0.99609375, 0.99609375, 0.98828125, 0.9453125, 0.99609375, 0.349609375, 0.5625, 0.9921875]]\n","[[0.98828125, 0.9921875, 0.99609375, 0.87890625, 0.9609375, 0.99609375, 0.75390625, 0.9921875]]\n","[[0.953125, 0.9609375, 0.22265625, 0.53125, 0.9921875, 0.96875, 0.9921875, 0.9921875]]\n","[[0.1484375, 0.09521484375, 0.9453125, 0.99609375, 1.0, 0.8515625, 0.9921875, 0.87890625]]\n","[[0.5625, 0.96875, 0.99609375, 0.9921875, 1.0, 0.99609375, 0.77734375, 0.98828125]]\n","[[0.99609375, 0.6796875, 0.0673828125, 0.1484375, 0.98828125, 0.9921875, 0.99609375, 0.984375]]\n","[[0.98828125, 1.0, 0.99609375, 0.99609375, 0.984375, 0.9609375, 0.96875, 0.0260009765625]]\n","[[0.99609375, 0.9921875, 0.99609375, 0.59375, 0.9765625, 0.9921875, 0.75390625, 0.9921875]]\n","[[0.98828125, 0.99609375, 0.984375, 0.376953125, 0.9765625, 0.98828125, 0.9921875, 0.9921875]]\n","[[0.9921875, 0.26953125, 0.94140625, 0.99609375, 0.98828125, 0.98828125, 0.98828125, 0.96875]]\n","[[1.0, 0.2021484375, 0.984375, 0.9921875, 0.81640625, 0.98046875, 1.0, 0.99609375]]\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 4.67 GiB. GPU 0 has a total capacity of 39.56 GiB of which 2.27 GiB is free. Process 1001707 has 37.27 GiB memory in use. Of the allocated memory 33.64 GiB is allocated by PyTorch, with 23.47 MiB allocated in private pools (e.g., CUDA Graphs), and 3.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-da46f2812e3c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrial_max_score_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrial_max_score_arr\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_maxk_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_of_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtrial_max_score_arr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnum_trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-279adcf7a6dc>\u001b[0m in \u001b[0;36m_maxk_sequence\u001b[0;34m(batch_of_prompts, config, llm, prm)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generated {len(c)} completions instead of {config.n}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_of_prompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     agg_scores = [\n\u001b[1;32m     68\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0maggregate_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg_strategy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/packages/search-and-learn/src/sal/models/reward_models.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, questions, outputs, batched, batch_size)\u001b[0m\n\u001b[1;32m    162\u001b[0m     ) -> list[list[float]]:\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatched\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Colab Notebooks/packages/search-and-learn/src/sal/models/reward_models.py\u001b[0m in \u001b[0;36m_score_batched\u001b[0;34m(self, questions, outputs, batch_size)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0minputs_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minputs2_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidate_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m                 scores = logits.softmax(dim=-1)[\n\u001b[1;32m    251\u001b[0m                     \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;31m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnum_logits_to_keep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.67 GiB. GPU 0 has a total capacity of 39.56 GiB of which 2.27 GiB is free. Process 1001707 has 37.27 GiB memory in use. Of the allocated memory 33.64 GiB is allocated by PyTorch, with 23.47 MiB allocated in private pools (e.g., CUDA Graphs), and 3.04 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"aff7452b860a4fefabfdd878e5fab729":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c881d6f3997c466e831432e49689a43d","IPY_MODEL_a33de001a7a044c3aa400b3178f15ff7","IPY_MODEL_150c565192124618b295bd3b515af960"],"layout":"IPY_MODEL_826576c1cb3548b9bb7c05bb1f37f765"}},"c881d6f3997c466e831432e49689a43d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4804b05baa46425b94f1032097f721ed","placeholder":"​","style":"IPY_MODEL_c90edb1c121249579f204680429632e2","value":""}},"a33de001a7a044c3aa400b3178f15ff7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_608abe2f22884ae0bfd6fafabe03e237","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02246503a0d44cd8911a704da5205a03","value":1}},"150c565192124618b295bd3b515af960":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b0d9248ab8a4fcc83f4897edd9cd1aa","placeholder":"​","style":"IPY_MODEL_a457a608de594b868e63f34bfef2aa3a","value":"Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01&lt;00:00,  1.86s/it]\n"}},"826576c1cb3548b9bb7c05bb1f37f765":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4804b05baa46425b94f1032097f721ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c90edb1c121249579f204680429632e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"608abe2f22884ae0bfd6fafabe03e237":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02246503a0d44cd8911a704da5205a03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b0d9248ab8a4fcc83f4897edd9cd1aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a457a608de594b868e63f34bfef2aa3a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68ed973a465042f59f8e18e5a5369653":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9b7c7ebbdb4845828e30cdfceb5e6d3b","IPY_MODEL_b9dc23f2b59544a09abdb8920610e6d7","IPY_MODEL_0c4d8271dee94e04af7b49cc8fa8ba1f"],"layout":"IPY_MODEL_4c08e1be2f2d48a9802dd34858079f29"}},"9b7c7ebbdb4845828e30cdfceb5e6d3b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f6004155b8945bc91c56f84946be216","placeholder":"​","style":"IPY_MODEL_74c04b0fc3fe4a1f97d17c2d2f31836d","value":"Loading checkpoint shards: 100%"}},"b9dc23f2b59544a09abdb8920610e6d7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7c6a5dddd894ba68deb88b7cc9cd0f8","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae61e060a981495480e0bd4db2f654ca","value":4}},"0c4d8271dee94e04af7b49cc8fa8ba1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37cea44a02b24cbd8e35c4f48bc4691b","placeholder":"​","style":"IPY_MODEL_e98fb062be9b422e8e32894fdb3d2f69","value":" 4/4 [00:06&lt;00:00,  1.48s/it]"}},"4c08e1be2f2d48a9802dd34858079f29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f6004155b8945bc91c56f84946be216":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c04b0fc3fe4a1f97d17c2d2f31836d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7c6a5dddd894ba68deb88b7cc9cd0f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae61e060a981495480e0bd4db2f654ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37cea44a02b24cbd8e35c4f48bc4691b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e98fb062be9b422e8e32894fdb3d2f69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}