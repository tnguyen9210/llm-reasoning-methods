{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f4eeddb-1d9e-4f0e-980a-3e51286da3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, psutil, gc\n",
    "import signal\n",
    "import json\n",
    "import pickle\n",
    "import pprint\n",
    "import time \n",
    "import tqdm\n",
    "\n",
    "import re\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf3f3b6-d27d-47af-a634-7229c124283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from vllm import LLM, SamplingParams, PoolingParams\n",
    "\n",
    "from sal.config import Config\n",
    "from sal.models.reward_models import PRM\n",
    "from sal.utils.score import aggregate_scores\n",
    "from sal.search.utils import build_conv, generate_k_steps, last\n",
    "\n",
    "from core.reward_models import RLHFFlow\n",
    "\n",
    "from datasets import Dataset, load_dataset\n",
    "\n",
    "from core import best_of_n\n",
    "from utils.load_data import load_data_prm800k\n",
    "from utils import grader \n",
    "from utils import grader2\n",
    "from utils import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe05c4c3-d898-4f0a-b332-e7ea2e70b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir\n",
    "base_dir = '/groups/kjun/tnn/datasets/'\n",
    "\n",
    "# dataset path\n",
    "data_dir = base_dir + \"/prm800k/math_splits\"\n",
    "# data_dir = base_dir + \"/math500\"\n",
    "\n",
    "# llm and prm path\n",
    "llm_dir = base_dir + \"/Llama-3.2-1B-Instruct-GGUF/Llama-3.2-1B-Instruct.Q4_K_M.gguf\"\n",
    "prm_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data-GGUF/Llama3.1-8B-PRM-Deepseek-Data.Q4_K_M.gguf\"\n",
    "\n",
    "llm_tokenizer_dir = base_dir + \"/Llama-3.2-1B-Instruct\"\n",
    "prm_tokenizer_dir = base_dir + \"/Llama3.1-8B-PRM-Deepseek-Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "191b9348-5a9e-45f0-94fa-a4061424fae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--- memory: 4.6037678718566895\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(llm_tokenizer_dir)\n",
    "llm_tf = AutoModelForCausalLM.from_pretrained(llm_tokenizer_dir).to(\"cuda:3\")\n",
    "# model_regular.generation_config.pad_token_id = tokenizer.eos_token_id\n",
    "gc.collect();torch.cuda.empty_cache();\n",
    "print('#--- memory:', torch.cuda.memory_allocated(3)/(1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63d686d8-825d-44e7-afbd-948e30e1d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "->\n",
      "## Step 1: Understand the problem\n",
      "The circle has center $Q$ and a radius of 14 inches. Two smaller semicircles are tangent to each other and to the larger semicircle. The problem asks for the radius of the smaller semicircle.\n",
      "\n",
      "->\n",
      "## Step 2: Recognize the relevant geometry\n",
      "The right angle formed by the radii with the common tangent lines is crucial. It implies a right-angled triangle $\triangle ABQ$, where $A$ is the center of the larger circle, $B$ is the point of tangency on the smaller semicircle, $Q$ is the center of the smaller circle, and $Q$ is the point of tangency with the larger semicircle.\n",
      "\n",
      "->\n",
      "## Step 3: Identify the right triangle\n",
      "To solve the problem efficiently, we can use the properties of right-angled triangles. We can see that $\triangle ABQ$ is an isosceles right triangle because both radii are of equal length.\n",
      "\n",
      "->\n",
      "## Step 4: Apply the Pythagorean Theorem\n",
      "Let's denote the radius of the smaller semicircle as $x$. Using the Pythagorean Theorem, we can relate the sides of the triangle. We know that $AQ = QB = 14$, and $AB = \\sqrt{14^2 + x^2}$. We can use the fact that $AB$ is the hypotenuse of the right triangle $\triangle ABQ$. We can thus write: $\\sqrt{14^2 + x^2} = \\sqrt{14^2 + 14^2}$\n",
      "\n",
      "->\n",
      "## Step 5: Solve for the radius of the smaller semicircle\n",
      "Now we can simplify the equation and solve for $x$: $\\sqrt{14^2 + x^2} = \\sqrt{2 \\cdot 14^2}$, $x = \\sqrt{2 \\cdot 14^2 - 14^2}$, $x = \\sqrt{28 \\cdot 14}$, $x = \\sqrt{392}$, $x = 14\\sqrt{2}$\n",
      "\n",
      "->\n",
      "The final answer is: oxed{14\\sqrt{2}}$\n"
     ]
    }
   ],
   "source": [
    "def split_steps(text):\n",
    "    # Find all start positions of steps\n",
    "    step_starts = [match.start() for match in re.finditer(r'## Step \\d+:', text)]\n",
    "    step_starts.append(len(text))  # Add end of text as final boundary\n",
    "\n",
    "    steps = []\n",
    "    for i in range(len(step_starts) - 1):\n",
    "        chunk = text[step_starts[i]:step_starts[i+1]]\n",
    "        steps.append(chunk.strip())\n",
    "\n",
    "    # Extend the last step to include final answer if present\n",
    "    if steps and r'\\boxed' in text:\n",
    "        # Append the last boxed line to the final step if not already included\n",
    "        final_answer_match = re.search(r'The final answer is:.*?\\\\boxed\\{.*?\\}', text)\n",
    "        if final_answer_match:\n",
    "            final_answer = final_answer_match.group(0).strip()\n",
    "            if final_answer not in steps[-1]:\n",
    "                steps[-1] += '\\n\\n' + final_answer\n",
    "\n",
    "    return steps\n",
    "\n",
    "def split_steps(text):\n",
    "    # Find all step headers and their positions\n",
    "    step_matches = list(re.finditer(r\"## Step \\d+\", text))\n",
    "    step_positions = [(m.start(), m.group(0)) for m in step_matches]\n",
    "\n",
    "    steps = []\n",
    "\n",
    "    # Extract each step block based on positions\n",
    "    for i in range(len(step_positions)):\n",
    "        start_idx = step_positions[i][0]\n",
    "        end_idx = step_positions[i + 1][0] if i + 1 < len(step_positions) else len(text)\n",
    "        # step_text = text[start_idx:end_idx]\n",
    "        step_text = text[start_idx:end_idx].strip()\n",
    "        steps.append(step_text)\n",
    "\n",
    "    if len(steps) == 0:\n",
    "        return steps \n",
    "\n",
    "    steps_adjusted = steps[:-1]\n",
    "    # print(steps_adjusted)\n",
    "    newlines = \"\\n\\n\"\n",
    "    # print(text)\n",
    "    # print(steps)\n",
    "    last_step = steps[-1].split(newlines)\n",
    "    # for step in last_step:\n",
    "    #     print(\"\\n->\")\n",
    "    #     print(step)\n",
    "    # print(last_step)\n",
    "    tmp_step = newlines.join(last_step[:-1])\n",
    "    tmp_step = tmp_step.strip()\n",
    "    steps_adjusted.append(tmp_step)\n",
    "    steps_adjusted.append(last_step[-1].strip())\n",
    "    \n",
    "    # for step in steps_adjusted:\n",
    "    #     print(\"\\n->\")\n",
    "    #     print(step)\n",
    "    # # print(steps)\n",
    "    # stop\n",
    "    # # Extract final answer sentence with \\boxed{}\n",
    "    # final_answer_match = re.search(r\"The final answer is:.*?\\\\boxed\\{.*?\\}\", text)\n",
    "    # final_answer = final_answer_match.group(0).strip() if final_answer_match else None\n",
    "\n",
    "    return steps_adjusted\n",
    "\n",
    "text = '''\n",
    "## Step 1: Understand the problem\n",
    "The circle has center $Q$ and a radius of 14 inches. Two smaller semicircles are tangent to each other and to the larger semicircle. The problem asks for the radius of the smaller semicircle.\n",
    "\n",
    "## Step 2: Recognize the relevant geometry\n",
    "The right angle formed by the radii with the common tangent lines is crucial. It implies a right-angled triangle $\\triangle ABQ$, where $A$ is the center of the larger circle, $B$ is the point of tangency on the smaller semicircle, $Q$ is the center of the smaller circle, and $Q$ is the point of tangency with the larger semicircle.\n",
    "\n",
    "## Step 3: Identify the right triangle\n",
    "To solve the problem efficiently, we can use the properties of right-angled triangles. We can see that $\\triangle ABQ$ is an isosceles right triangle because both radii are of equal length.\n",
    "\n",
    "## Step 4: Apply the Pythagorean Theorem\n",
    "Let's denote the radius of the smaller semicircle as $x$. Using the Pythagorean Theorem, we can relate the sides of the triangle. We know that $AQ = QB = 14$, and $AB = \\sqrt{14^2 + x^2}$. We can use the fact that $AB$ is the hypotenuse of the right triangle $\\triangle ABQ$. We can thus write: $\\sqrt{14^2 + x^2} = \\sqrt{14^2 + 14^2}$\n",
    "\n",
    "## Step 5: Solve for the radius of the smaller semicircle\n",
    "Now we can simplify the equation and solve for $x$: $\\sqrt{14^2 + x^2} = \\sqrt{2 \\cdot 14^2}$, $x = \\sqrt{2 \\cdot 14^2 - 14^2}$, $x = \\sqrt{28 \\cdot 14}$, $x = \\sqrt{392}$, $x = 14\\sqrt{2}$\n",
    "\n",
    "\n",
    "The final answer is: $\\boxed{14\\sqrt{2}}$\n",
    "'''\n",
    "steps = split_steps(text)\n",
    "for step in steps:\n",
    "    print(\"\\n->\")\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98dfb27-fdfc-4726-9294-c3310d771e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a2cd9228f34502b7d85805560e3c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "level = 4\n",
    "dataset_by_level = dataset.filter(lambda example: example['level'] == level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ece7e03-63f1-4145-9223-dc58cd5d23fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['problem', 'solution', 'answer', 'subject', 'level', 'unique_id', 'completions', 'scores', 'pred', 'completion_tokens', 'agg_scores', 'pred_weighted@4', 'pred_maj@4', 'pred_naive@4', 'pred_weighted@8', 'pred_maj@8', 'pred_naive@8', 'pred_weighted@16', 'pred_maj@16', 'pred_naive@16', 'pred_weighted@32', 'pred_maj@32', 'pred_naive@32', 'pred_weighted@64', 'pred_maj@64', 'pred_naive@64', 'pred_weighted@128', 'pred_maj@128', 'pred_naive@128'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_by_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "780f96fa-76da-41fc-942a-e80ae8853336",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'indent' is an invalid keyword argument for dump()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 105\u001b[0m\n\u001b[1;32m    101\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(all_data, fout, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    104\u001b[0m config \u001b[38;5;241m=\u001b[39m Config()\n\u001b[0;32m--> 105\u001b[0m \u001b[43mextract_completion_embeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_by_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[43], line 101\u001b[0m, in \u001b[0;36mextract_completion_embeds\u001b[0;34m(dataset_by_level, config)\u001b[0m\n\u001b[1;32m     98\u001b[0m             all_data\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fout:\n\u001b[0;32m--> 101\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(all_data, fout, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'indent' is an invalid keyword argument for dump()"
     ]
    }
   ],
   "source": [
    "class TimeoutException(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutException()\n",
    "    \n",
    "def run_with_timeout(fn_extract_answer, fn_grade, completion, gt_answer, timeout=2):\n",
    "    # Set the signal handler for SIGALRM\n",
    "    signal.signal(signal.SIGALRM, timeout_handler)\n",
    "    signal.alarm(timeout)  # Schedule an alarm after `timeout` seconds\n",
    "    try:\n",
    "        c_answer = fn_extract_answer(completion, 'math')\n",
    "        result = fn_grade(c_answer, gt_answer)\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout: {completion}\")\n",
    "        c_answer = None\n",
    "        result = None\n",
    "    finally:\n",
    "        signal.alarm(0)  # Cancel alarm if function returns early\n",
    "    return c_answer, result\n",
    "\n",
    "\n",
    "\n",
    "def extract_completion_embeds(dataset_by_level, level, config):\n",
    "    all_data = []\n",
    "\n",
    "    # go through each problem/prompt \n",
    "    for q_idx, data in enumerate(dataset_by_level):\n",
    "        if q_idx > 2:\n",
    "            continue\n",
    "        # pprint.pprint(data)\n",
    "        # print(len(data[\"scores\"]))\n",
    "    \n",
    "        # extract the problem and grounth truth answer (gt_answer)\n",
    "        problem = data[\"problem\"]\n",
    "        gt_cot, gt_answer  = parser.parse_ground_truth(data, 'math')\n",
    "    \n",
    "        # go through each completion\n",
    "        cnt = 0\n",
    "        for c_idx, completion in enumerate(data['completions']):\n",
    "            # if depth >= len(scores):\n",
    "            #     continue\n",
    "            if c_idx > 5:\n",
    "                continue\n",
    "    \n",
    "            # check whether the completion provides the \n",
    "            c_answer, is_correct = run_with_timeout(parser.extract_answer, grader2.math_equal, completion, gt_answer)\n",
    "            if is_correct is None: # skip the completion that can not be evaluated\n",
    "                continue \n",
    "    \n",
    "            # split the completion into steps\n",
    "            steps = completion.split(\"\\n\\n\")\n",
    "            current_text = \"\"\n",
    "            \n",
    "            for s_idx, step in enumerate(tqdm(steps, desc=\"Processing steps\")):\n",
    "                # add step to current_text \n",
    "                current_text += step \n",
    "                # print(current_text)\n",
    "                convs = [\n",
    "                    build_conv(problem, current_text, config.system_prompt)\n",
    "                ]            \n",
    "    \n",
    "                templated_convs = tokenizer.apply_chat_template(\n",
    "                    convs,\n",
    "                    add_generation_prompt=False,\n",
    "                    continue_final_message=True, # if False, add <|eot_id|> into the message\n",
    "                    tokenize=False,\n",
    "                )\n",
    "                \n",
    "                inputs = tokenizer(templated_convs[0], return_tensors=\"pt\").to(llm_tf.device)\n",
    "    \n",
    "                with torch.no_grad():\n",
    "                    outputs = llm_tf(**inputs, output_hidden_states=True)\n",
    "        \n",
    "                    # Get last_token_embeds\n",
    "                    last_hidden_state = outputs.hidden_states[-1]\n",
    "                    last_token_embeds = last_hidden_state[:, -1, :].squeeze(0).detach().cpu().numpy()\n",
    "                    \n",
    "                    # Compute otuput_log_prob\n",
    "                    # Prepare labels: shift input_ids to the right by one\n",
    "                    labels = inputs['input_ids'][:, 1:]   \n",
    "                    shifted_logits = outputs.logits[:, :-1, :]\n",
    "                    loss_fct = CrossEntropyLoss(reduction='sum')\n",
    "                    completion_log_prob = -loss_fct(shifted_logits.view(-1, shifted_logits.size(-1)), labels.view(-1)).detach().cpu().numpy()\n",
    "\n",
    "                x = defaultdict()\n",
    "                x[\"problem\"] = problem                                   # \n",
    "                x[\"level\"] = level                                       # the difficulty level\n",
    "                x[\"step_num\"] = s_idx                                    # the current step #\n",
    "                x[\"current_text\"] = current_text                         # the current text includes all steps up to this point\n",
    "                x[\"is_completed\"] = 1 if s_idx == len(steps) - 1 else 0  # whether the current step is the last step \n",
    "                x[\"gt\"] = gt_answer                                      # ground-truth answer\n",
    "                x[\"pred\"] = c_answer                                     # prediction extracted from the trajectory/completion\n",
    "                x[\"is_correct\"] = is_correct                             # whether the trajectory/completion leads to the correct answer              \n",
    "                x[\"embeds\"] = last_token_embeds                          # the hidden embeds of the last token\n",
    "                x[\"log_prob\"] = completion_log_prob                      # the log probability of the completion\n",
    "    \n",
    "                all_data.append(x)\n",
    "\n",
    "    with open(f\"results/{config_name}.pkl\", 'w') as fout:\n",
    "        pickle.dump(all_data, fout)\n",
    "\n",
    "\n",
    "level = 4\n",
    "config_name = \"bon--n-256--level-{level}--train--v01--chunk-0_200--trial-0\"\n",
    "dataset = load_dataset(\"json\", data_files = f\"results/{config_name}.jsonl\", split='train')\n",
    "dataset_by_level = dataset.filter(lambda example: example['level'] == level)\n",
    "\n",
    "config = Config()\n",
    "extract_completion_embeds(dataset_by_level, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
